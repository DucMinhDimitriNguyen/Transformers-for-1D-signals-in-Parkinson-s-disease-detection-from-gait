{"cells":[{"cell_type":"markdown","metadata":{"id":"3ea99e5e"},"source":["Parkinson detection"],"id":"3ea99e5e"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1645536987947,"user":{"displayName":"Serge Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiIsf8tpj8SUvq-Tvdf9MrB8oxBk6kwWurlI9V1aA=s64","userId":"05009995910480739700"},"user_tz":-60},"id":"ODITyDNFRzg9","outputId":"eaba8582-f882-4d37-cd32-50a513316445"},"outputs":[{"output_type":"stream","name":"stdout","text":["              total        used        free      shared  buff/cache   available\n","Mem:            25G        622M         22G        1.2M        2.1G         24G\n","Swap:            0B          0B          0B\n"]}],"source":["!free -h"],"id":"ODITyDNFRzg9"},{"cell_type":"markdown","metadata":{"id":"b9646f29"},"source":["Algo"],"id":"b9646f29"},{"cell_type":"code","execution_count":null,"metadata":{"id":"24d186da"},"outputs":[],"source":["# -*- coding: utf-8 -*-\n","\"\"\"\n","@author: Nguyen Duc Minh\n","\"\"\"\n","\n","import numpy as np\n","np.random.seed(2)\n","import tensorflow as tf\n","tf.config.run_functions_eagerly(True)\n","#tf.enable_eager_execution()\n","from tensorflow.keras import layers\n","from tensorflow.keras import Input\n","from tensorflow.keras import optimizers\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Dropout, Flatten, Conv1D\n","\n","from tensorflow.keras.layers import Dense, Flatten, Dropout\n","from tensorflow.keras import backend as K\n","import uuid\n","\n","def add_pos_2(input,nb):\n","    input_pos_encoding = tf.constant(nb, shape=[input.shape[1]], dtype=\"int32\")/input.shape[1]\n","    input_pos_encoding = tf.cast(tf.reshape(input_pos_encoding, [1,10]),tf.float32)\n","    input = tf.add(input ,input_pos_encoding)\n","    return input\n","\n","def stack_block_transformer(num_transformer_blocks):\n","    input1 = keras.Input(shape=(100, 1))\n","    x = input1\n","    for _ in range(num_transformer_blocks):\n","        x = transformer_encoder(x,100,2)\n","    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n","    x = layers.Dense(10, activation='selu')(x)\n","    return input1,x\n","\n","def stack_block_transformer_spatial(num_transformer_blocks,x):\n","  for _ in range(num_transformer_blocks):\n","      x = transformer_encoder(x,10*18,2)\n","  x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n","\n","  return x\n","\n","def transformer_encoder(inputs,key_dim,num_heads):\n","    dropout=0.1\n","    # Normalization and Attention\n","    print(\"transformer_encoder\",inputs.shape)\n","    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n","    x = layers.MultiHeadAttention(\n","        key_dim=key_dim, num_heads=num_heads\n","    )(x, x)\n","    x = layers.Dropout(dropout)(x)\n","    res = x + inputs\n","\n","    # Feed Forward Part\n","    x = layers.LayerNormalization(epsilon=1e-6)(res)\n","    x = layers.Dense(key_dim, activation='softmax')(x)\n","    return x + res\n","\n","\n","def multiple_transformer(nb):\n","    '''\n","\n","    :param nb: number of features ( indicates the number of parallel branches)\n","    :return:\n","    '''\n","    # initialise with the first input\n","\n","    num_transformer_blocks = 2  #hyperparameter\n","    input_, transformer_ = stack_block_transformer(num_transformer_blocks)\n","    transformers = []\n","    inputs = []\n","    transformers.append(transformer_)\n","    inputs.append(input_)\n","    for i in range(1,nb ):\n","        input_i, transformer_i = stack_block_transformer(num_transformer_blocks)\n","        inputs.append(input_i) \n","        transformer_i = add_pos_2(transformer_i,i)\n","        transformers.append(transformer_i)\n","  \n","    x = layers.concatenate(transformers, axis=-1)\n","    x = tf.expand_dims(x, -1) #-1 denotes the last dimension\n","    x = stack_block_transformer_spatial(num_transformer_blocks,x)\n","    x = Dropout(0.1)(x)\n","    x = layers.Dense(100, activation='selu')(x)\n","    x = Dropout(0.1)(x)\n","    x = layers.Dense(20, activation='selu')(x)\n","    x = Dropout(0.1)(x)\n","    answer = layers.Dense(1, activation='sigmoid')(x)\n","  \n","    model = Model(inputs, answer)\n","    opt = optimizers.RMSprop(lr=0.001)\n","    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'],experimental_run_tf_function=False)\n","    print(model.summary())\n","    return model\n","\n","\n","def multiple_transformer_5_level(nb):\n","    '''\n","    Model for severity prediction , 5 classes output\n","    :param nb:  number of parallel branch\n","    :return:\n","    '''\n","\n","  # initialise with the first input\n","\n","    num_transformer_blocks = 2  #hyperparameter\n","    input_, transformer_ = stack_block_transformer(num_transformer_blocks)\n","    transformers = []\n","    inputs = []\n","    transformers.append(transformer_)\n","    inputs.append(input_)\n","    for i in range(1,nb ):\n","        input_i, transformer_i = stack_block_transformer(num_transformer_blocks)\n","        inputs.append(input_i)\n","        transformer_i = add_pos_2(transformer_i,i)\n","        transformers.append(transformer_i)\n","  \n","    x = layers.concatenate(transformers, axis=-1)\n","    x = tf.expand_dims(x, -1) #-1 denotes the last dimension\n","    x = stack_block_transformer_spatial(num_transformer_blocks,x)\n","    x = Dropout(0.1)(x)\n","    x = layers.Dense(100, activation='selu')(x)\n","    x = Dropout(0.1)(x)\n","    x = layers.Dense(20, activation='selu')(x)\n","    x = Dropout(0.1)(x)\n","    answer = layers.Dense(5, activation='sigmoid')(x)\n","  \n","    model = Model(inputs, answer)\n","    opt = optimizers.RMSprop(lr=0.001)\n","    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'],experimental_run_tf_function=False)\n","    print(model.summary())\n","    return model\n","\n","\n"],"id":"24d186da"},{"cell_type":"markdown","metadata":{"id":"7359e3aa"},"source":["Data_utils"],"id":"7359e3aa"},{"cell_type":"code","execution_count":null,"metadata":{"id":"ea853f10"},"outputs":[],"source":["# -*- coding: utf-8 -*-\n","\"\"\"\n","\n","\"\"\"\n","import glob\n","import os\n","import random\n","import sys\n","from tensorflow import keras\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from tensorflow.keras.utils import to_categorical\n","\n","sys.path.append('../src')\n","np.random.seed(2)\n","\n","\n","\n","class Data:\n","\n","    def __init__(self,  input_data,  deep, gait_cycle, step=50, features=np.arange(1, 19), pk_level = True):\n","        '''\n","\n","        :param load_or_get:  1: load data , 0: load preloaded datas ( npy)\n","        :param deep:  data in the format for deep learning algorithms\n","        :param gait_cycle: number of gait cycle per signal\n","        :param step: overlap between gait signals\n","        :param features: signals to be loaded ( coming from sensors)\n","        :param pk_level: if true , y is the parkinson level according\n","        '''\n","\n","        self.deep = deep\n","        self.step = step\n","        self.nb_gait_cycle = gait_cycle\n","\n","\n","        self.features_to_load = features\n","        self.nb_features = self.features_to_load.shape[0]\n","        ###############\n","        self.X_data = np.array([])  # np.ones((self.nb_gait_cycle,self.nb_features))\n","        self.y_data = np.array([])\n","        self.nb_data_per_person = np.array([0])\n","\n","\n","        files = sorted(glob.glob(os.path.join(input_data, '*txt')))\n","        self.ctrl_list = []\n","        self.pk_list = []\n","        for file in files:\n","\n","            if file.find(\".txt\") != -1:  # if control (\"01.txt\")\n","                if file.find(\"Co\") != -1:  # if control\n","                    self.ctrl_list.append(file)\n","                elif file.find(\"Pt\") != -1:  # if control\n","                    if pk_level:\n","                        if  file.find('SiPt02')!= -1:\n","                            pass\n","                        elif file.find('SiPt07')!= -1:\n","                            pass\n","                        else:\n","                            self.pk_list.append(file)\n","                    else :\n","                        self.pk_list.append(file)\n","\n","        random.shuffle(self.ctrl_list)\n","        random.shuffle(self.pk_list)\n","        self.pk_level = pk_level\n","        if pk_level == True:\n","            self.levels = pd.read_csv( os.path.join(input_data, \"demographics.csv\"))\n","            self.levels.set_index('ID', inplace=True)\n","        self.load(norm=None)\n","     \n","    def add_pos(self,input):\n","       # Positional encoding\n","        input_pos_encoding = tf.range(input.shape[1])/input.shape[1]\n","        input_pos_encoding = tf.expand_dims(input_pos_encoding, -1)\n","        input_pos_encoding= tf.cast(tf.tile(input_pos_encoding, [1,input.shape[2]]),tf.float32)\n","        # Add the positional encoding\n","        input = input + input_pos_encoding\n","        return input\n","\n","\n","    def separate_fold(self, fold_number, total_fold=10):\n","        '''\n","\n","        :param fold_number: Fold number\n","        :param total_fold: Total number of fols\n","        :return:\n","        '''\n","        proportion = 1 / total_fold  # .10 for 10 folds\n","        X = [self.X_ctrl, self.X_park]\n","        y = [self.y_ctrl, self.y_park]\n","        patients = [self.nb_data_per_person[:self.last_ctrl_patient], self.nb_data_per_person[self.last_ctrl_patient:]] # counts separated by classe\n","        patients[1]= patients[1] - patients[1][0]\n","        diff_count = np.diff(self.nb_data_per_person)\n","        diff_count = [diff_count[:self.last_ctrl_patient], diff_count[self.last_ctrl_patient:]]\n","        self.count_val = np.array([0])\n","        self.count_train = np.array([0])\n","        for i in range(len(X)):\n","            nbr_patients =  int(len(patients[i]) *proportion)\n","            start_patient = int(fold_number*nbr_patients )\n","            end_patient = (fold_number+1)*nbr_patients\n","            id_start = patients[i][start_patient]  # segment start\n","            id_end = patients[i][end_patient]  # end segment\n","            if i ==0 :\n","                self.X_val = X[i][id_start:id_end,:,:]\n","                self.X_train = np.delete(X[i], np.arange(id_start,id_end) , 0)\n","\n","                self.y_val = y[i][id_start:id_end]\n","                self.y_train = np.delete(y[i], np.arange(id_start,id_end) , 0)\n","\n","\n","                self.count_val = np.append(self.count_val, diff_count[i][start_patient: end_patient])\n","                self.count_train = np.append(self.count_train, np.delete(diff_count[i], np.arange(start_patient, end_patient)))\n","\n","\n","\n","            else:\n","                start_patient = start_patient #+ patients[0].shape[0]  # patients0.shape 0 is the number of patients in the first class\n","                end_patient =  end_patient# +patients[0].shape[0]\n","                self.X_val = np.vstack((self.X_val, X[i][id_start:id_end,:,:]))\n","                self.X_train = np.vstack((self.X_train, np.delete(X[i], np.arange(id_start,id_end) , 0) ))\n","\n","                self.y_val = np.vstack((self.y_val, y[i][id_start:id_end] ))\n","                self.y_train = np.vstack((self.y_train, np.delete(y[i], np.arange(id_start,id_end) , 0) ))\n","\n","                self.count_val = np.append( self.count_val , diff_count[i][start_patient: end_patient])\n","                self.count_train = np.append(self.count_train,np.delete(diff_count[i], np.arange(start_patient, end_patient)) )\n","\n","        self.count_val = np.cumsum(self.count_val)\n","        self.count_train = np.cumsum(self.count_train )\n","        self.X_val = layers.LayerNormalization(epsilon=1e-6)(self.X_val)\n","        self.X_train = layers.LayerNormalization(epsilon=1e-6)(self.X_train)\n","        self.X_val = self.add_pos(self.X_val)\n","        self.X_train = self.add_pos(self.X_train)\n","      \n","\n","    def load(self, norm = 'std'):\n","        print(\"load training control \")\n","        self.load_data(self.ctrl_list, 0)\n","        if self.deep == 1:\n","            self.last_ctrl= self.X_data.shape[2]\n","            self.last_ctrl_patient = len(self.nb_data_per_person)\n","        print(\"load training parkinson \")\n","\n","\n","        self.load_data(self.pk_list, 1)  # ncycle, nfeature, nombre de data\n","\n","\n","        ## all datas are loaded at this point, preprocessing now\n","        if self.deep == 1:\n","            self.X_data = self.X_data.transpose(2,0 , 1)  #0, 1\n","\n","            if norm == 'std ':\n","                self.normalize()\n","            elif norm == 'l2':\n","                self.X_data = self.normalize_l2(self.X_data)\n","\n","        if self.pk_level:\n","            self.one_hot_encoding()\n","\n","        if self.deep == 1:\n","            self.X_ctrl = self.X_data[:self.last_ctrl]\n","            self.y_ctrl =  self.y_data[:self.last_ctrl]\n","            self.X_park = self.X_data[self.last_ctrl:]\n","            self.y_park = self.y_data[self.last_ctrl:]\n","\n","        print(\"saving training \")\n","        np.save(\"Xdata\", self.X_data)\n","        np.save(\"ydata\", self.y_data)\n","        np.save('data_person',self.nb_data_per_person)\n","        np.save('ctrl_list', self.ctrl_list)\n","        np.save('pk_list', self.pk_list)\n","\n","    def normalize(self):\n","        '''\n","\n","        :return: Normalize to have a mean =  and std =1\n","        '''\n","        mean_train = np.mean(self.X_data,(0,1))\n","        std_train = np.std(self.X_data,(0,1))\n","        self.X_data= abs((self.X_data - mean_train) / std_train)\n","        #self.X_test= (self.X_test - mean_train) / std_train\n","    def one_hot_encoding(self):\n","        '''\n","\n","        :return: return one hot encoding vector for severity prediction\n","        '''\n","        self.y_data[self.y_data<=4]=0\n","        self.y_data[(4<self.y_data) & (self.y_data <15)]=1\n","        self.y_data[(15<= self.y_data) & (self.y_data<25)]=2\n","        self.y_data[(25<= self.y_data) & (self.y_data<35)] = 3\n","        self.y_data[35<= self.y_data] = 4\n","        np.set_printoptions(threshold=sys.maxsize)\n","        # self.y_data = np.squeeze(self.y_data)\n","        #self.y_data = self.y_data[~np.isnan(self.y_data)] # Line 2\n","        self.y_data = np.nan_to_num(self.y_data)\n","        print(self.y_data)\n","        print(self.y_data.size)\n","        self.y_data = to_categorical(self.y_data)\n","\n","    def normalize_l2(self, data):\n","        '''\n","\n","        :param data:  Function to perform L2 normalization\n","        :return:\n","        '''\n","        data = keras.backend.l2_normalize(data, axis=(1, 2))\n","        data = tf.keras.backend.get_value(data)\n","        return data\n","\n","\n","    def load_data(self, liste, y):\n","        '''\n","\n","        :param liste: list of patients filepaths\n","        :param y: 0 for control, 1 for parkinson\n","        :return:\n","        '''\n","\n","        for i in range(0, len(liste)):\n","            datas = np.loadtxt(liste[i])  # num cycle, n features\n","            datas = datas[:, self.features_to_load]\n","            print(datas.shape[0])\n","            if  self.pk_level :\n","                print(\"1\")\n","                y =self.find_level(liste[i])\n","\n","            if self.deep == 1:\n","                print(\"2\")\n","                X_data, y_data , self.nb_data_per_person = self.generate_datas(datas, y, self.nb_data_per_person)\n","              \n","            else:\n","                print(\"3\")\n","                X_data, y_data = self.generate_datas_ml(datas, y)\n","            if (self.X_data).size == 0:\n","                print(\"4\")\n","                self.X_data = X_data\n","                self.y_data = y_data\n","            else:\n","                print(\"5\")\n","                if self.deep == 1:\n","                    print(\"6\")\n","                    self.X_data = np.dstack((self.X_data, X_data))\n","                else:\n","                    print(\"7\")\n","                    self.X_data = np.vstack((self.X_data, X_data))  # shape nb data --- vector size\n","                self.y_data = np.vstack((self.y_data, y_data))\n","\n","            print(X_data.shape, self.X_data.shape,flush=True)\n","           \n","\n","\n","    def find_level(self,file):\n","        '''\n","\n","        :param file: Dataframe\n","        :return:\n","        '''\n","        start = '../data/'\n","        end = '_'\n","        id = (file.split(start))[1].split(end)[0]\n","        y = self.levels.loc[id,'UPDRS']\n","        return y\n","\n","\n","    def generate_datas(self, datas, y, data_list):\n","        '''\n","\n","        :param datas:  datas loaded for 1 patient\n","        :param y: label of the patient\n","        :param data_list: list containing the number of segments per patients\n","        :return:\n","        '''\n","        count = 0\n","        X_data = np.array([])\n","        y_data = np.array([])\n","        nb_datas = int(datas.shape[0] - self.nb_gait_cycle)\n","        for start in range(0, nb_datas, self.step):\n","            end = start + self.nb_gait_cycle\n","            data = datas[start:end, :]\n","            if X_data.size == 0:\n","                X_data = data\n","                y_data = y\n","            else:\n","                if (self.deep == 1):\n","                    X_data = np.dstack((X_data, data))\n","                else:\n","                    X_data = np.vstack((X_data, data))\n","                y_data = np.vstack((y_data, y))\n","            count = count + 1\n","        data_list = np.append(data_list, count+ data_list[-1])\n","        return X_data, y_data, data_list\n","\n","\n","    def get_datas(self):\n","        return self.X_data, self.y_data, self.X_test, self.y_test, self.X_val, self.y_val\n","\n"],"id":"ea853f10"},{"cell_type":"markdown","metadata":{"id":"248c0eb7"},"source":["results"],"id":"248c0eb7"},{"cell_type":"code","execution_count":null,"metadata":{"id":"662c1ad3"},"outputs":[],"source":["import os\n","import numpy as np\n","from sklearn.metrics import confusion_matrix,  classification_report, accuracy_score\n","from scipy import stats\n","import pandas as pd\n","class Results:\n","    def __init__(self, filename_seg, filename_patient):\n","        '''\n","\n","        :param filename_seg:  Filename  (.csv) where to save results at the segment levels\n","        :param filename_patient: Filename  (.csv) where to save results at the patient levels\n","        '''\n","        self.results_patients = np.zeros(3)\n","        self.results_segments = np.zeros(3)\n","        self.filename_seg = filename_seg\n","        self.filename_patient = filename_patient\n","    def add_result( self,res, accuracy,  segments = True  ):\n","        '''\n","\n","        :param res: result of classification report (sklearn )\n","        :param accuracy:\n","        :param segments: 1 to add results at the segment level\n","        :return:\n","        '''\n","        if segments:\n","            specificity = res['0.0']['recall']\n","            sensitivy =  res['1.0']['recall']\n","        else:\n","            specificity = res['0']['recall']\n","            sensitivy =  res['1']['recall']\n","        all = np.array([specificity, sensitivy, accuracy])\n","\n","        if segments:\n","            self.results_segments = np.vstack((self.results_segments, all))\n","        else:\n","            self.results_patients = np.vstack((self.results_patients, all ))\n","\n","    def validate_patient(self, model, x_val, y_val, count):\n","        '''\n","\n","        :param model: trained model after 1 fold of cross validation\n","        :param x_val: x_Val for 1 forld of cross validation\n","        :param y_val: y_Val for 1 forld of cross validation\n","        :param count: vector containing the number of segments per patient\n","        :return:  save the results of the fold\n","\n","        '''\n","        ## per segments\n","        pred_seg = model.predict(np.split(x_val, x_val.shape[2], axis=2))\n","        res = classification_report(np.rint(y_val), np.rint(pred_seg), output_dict = True )\n","        acc = accuracy_score(np.rint(y_val), np.rint(pred_seg))\n","        self.add_result(res, acc,True  )\n","\n","        eval = []\n","        y = []\n","        pred = []\n","        for m in range(1, len(count)):\n","            i = count[m]\n","            j = count[m - 1]\n","            score = model.evaluate(np.split(x_val[j:i, :, :], x_val.shape[2], axis=2), y_val[j:i])\n","            eval.append(score)\n","            y.append(np.int(np.mean(y_val[j:i])))\n","            p = np.rint(model.predict(np.split(x_val[j:i, :, :], x_val.shape[2], axis=2)))\n","            pred.append(np.mean(p))\n","\n","        res = classification_report(y, np.rint(pred), output_dict = True )\n","        print(classification_report(y, np.rint(pred)))\n","\n","        acc = accuracy_score(np.rint(y), np.rint(pred))\n","        self.add_result(res, acc, False )\n","\n","        #np.savetxt(self.filename_patient, self.results_patients, delimiter=\",\")\n","        #np.savetxt(self.filename_seg, self.results_segments, delimiter=\",\")\n","        res_segments_dict = {'Specificity': self.results_segments[1:,0],'Sensitivity': self.results_segments[1:,1],'Accuracy': self.results_segments[1:,2]  }\n","        df = pd.DataFrame.from_dict(res_segments_dict)\n","        df.to_csv(self.filename_seg)\n","        res_patients_dict =  {'Specificity': self.results_patients[1:,0],'Sensitivity': self.results_patients[1:,1],'Accuracy': self.results_patients[1:,2]  }\n","        df = pd.DataFrame.from_dict(res_patients_dict)\n","        df.to_csv(self.filename_patient)\n","\n","\n","\n","class Results_level:\n","    '''\n","    Class to save results for severity prediction\n","    '''\n","    def __init__(self, filename_seg, filename_patient, dir):\n","        '''\n","\n","        :param filename_seg: filename (csv) where to save the results\n","        :param filename_patient:\n","        :param dir: directory where results files are saved\n","        '''\n","        self.results_patients = np.zeros(1)\n","        self.results_segments = np.zeros(1)\n","        self.filename_seg = filename_seg\n","        self.filename_patient = filename_patient\n","        self.gt = np.array([])\n","        self.pred = np.array([])\n","        self.dir = dir\n","    def add_result( self,res, accuracy,  segments = True  ):\n","\n","        all = np.array([ accuracy])\n","\n","        if segments:\n","            self.results_segments = np.vstack((self.results_segments, all))\n","        else:\n","            self.results_patients = np.vstack((self.results_patients, all ))\n","\n","\n","\n","    def validate_patient(self, model, x_val, y_val, count):\n","        '''\n","\n","        :param model: trained model after 1 fold of cross validation\n","        :param x_val: x_Val for 1 forld of cross validation\n","        :param y_val: y_Val for 1 forld of cross validation\n","        :param count: vector containing the number of segments per patient\n","        :return:  save the results of the fold\n","\n","        '''\n","        ## per segments\n","        pred_seg = model.predict(np.split(x_val, x_val.shape[2], axis=2))\n","        res = classification_report(np.rint(y_val), np.rint(pred_seg), output_dict = True )\n","        acc = accuracy_score(np.rint(y_val), np.rint(pred_seg))\n","        self.add_result(res, acc,True  )\n","\n","        eval = []\n","        y = []\n","        pred = []\n","        for m in range(1, len(count)):\n","            i = count[m]\n","            j = count[m - 1]\n","            score = model.evaluate(np.split(x_val[j:i, :, :], x_val.shape[2], axis=2), y_val[j:i])\n","            eval.append(score)\n","            y_gt = np.argmax(y_val[j:i],1)\n","            y_gt , _ = stats.mode(y_gt, axis = None)\n","            y.append(y_gt[0])\n","            p = np.rint(model.predict(np.split(x_val[j:i, :, :], x_val.shape[2], axis=2)))\n","            p = np.argmax(p, 1 )\n","            p, _ = stats.mode(p, axis=None)\n","            pred.append(p[0])\n","\n","        res = classification_report(y, np.rint(pred), output_dict = True )\n","        print(classification_report(y, np.rint(pred)))\n","        self.gt = np.append(self.gt, y)\n","        self.pred = np.append(self.pred, np.rint(pred))\n","        acc = accuracy_score(np.rint(y), np.rint(pred))\n","        self.add_result(res, acc, False )\n","        res_segments_dict = {'Accuracy': self.results_segments[1:,0]}\n","        df = pd.DataFrame.from_dict(res_segments_dict)\n","        df.to_csv(self.filename_seg)\n","        res_patients_dict =  {'Accuracy': self.results_patients[1:,0]}\n","        df = pd.DataFrame.from_dict(res_patients_dict)\n","        df.to_csv(self.filename_patient)\n","        print(res)\n","\n","\n","\n","\n","    def write_results(self):\n","        '''\n","        Called at the end to write the final result files\n","        :return:\n","        '''\n","        res_segments_dict = {'Accuracy': self.results_segments[1:,0]}\n","        df = pd.DataFrame.from_dict(res_segments_dict)\n","        df.to_csv(self.filename_seg)\n","        res_patients_dict =  {'Accuracy': self.results_patients[1:,0]}\n","        df = pd.DataFrame.from_dict(res_patients_dict)\n","        df.to_csv(self.filename_patient)\n","        file_pred = os.path.join(self.dir, 'pred.csv')\n","        file_gt = os.path.join(self.dir, 'gt.csv')\n","        np.savetxt(file_pred, self.pred, delimiter=\",\" )\n","        np.savetxt(file_gt,self.gt, delimiter=\",\")\n","        res = classification_report(self.gt, self.pred)\n","        print(res)\n","        self.cm = confusion_matrix(self.gt, self.pred)\n","        file_conf_matrx = os.path.join(self.dir, 'confusion_matrix.csv')\n","        np.savetxt(file_conf_matrx, self.cm, delimiter=\",\")\n"],"id":"662c1ad3"},{"cell_type":"markdown","metadata":{"id":"c82fd0f8"},"source":["Train"],"id":"c82fd0f8"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"31745805","executionInfo":{"status":"ok","timestamp":1645573867614,"user_tz":-60,"elapsed":24394393,"user":{"displayName":"Serge Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiIsf8tpj8SUvq-Tvdf9MrB8oxBk6kwWurlI9V1aA=s64","userId":"05009995910480739700"}},"outputId":"8807b236-52d7-4297-e2ef-947e2d41360e"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [4.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [2.]]\n","65433\n","saving training \n","transformer_encoder (None, 100, 1)\n","transformer_encoder (None, 100, 100)\n","transformer_encoder (None, 100, 1)\n","transformer_encoder (None, 100, 100)\n","transformer_encoder (None, 100, 1)\n","transformer_encoder (None, 100, 100)\n","transformer_encoder (None, 100, 1)\n","transformer_encoder (None, 100, 100)\n","transformer_encoder (None, 100, 1)\n","transformer_encoder (None, 100, 100)\n","transformer_encoder (None, 100, 1)\n","transformer_encoder (None, 100, 100)\n","transformer_encoder (None, 100, 1)\n","transformer_encoder (None, 100, 100)\n","transformer_encoder (None, 100, 1)\n","transformer_encoder (None, 100, 100)\n","transformer_encoder (None, 100, 1)\n","transformer_encoder (None, 100, 100)\n","transformer_encoder (None, 100, 1)\n","transformer_encoder (None, 100, 100)\n","transformer_encoder (None, 100, 1)\n","transformer_encoder (None, 100, 100)\n","transformer_encoder (None, 100, 1)\n","transformer_encoder (None, 100, 100)\n","transformer_encoder (None, 100, 1)\n","transformer_encoder (None, 100, 100)\n","transformer_encoder (None, 100, 1)\n","transformer_encoder (None, 100, 100)\n","transformer_encoder (None, 100, 1)\n","transformer_encoder (None, 100, 100)\n","transformer_encoder (None, 100, 1)\n","transformer_encoder (None, 100, 100)\n","transformer_encoder (None, 100, 1)\n","transformer_encoder (None, 100, 100)\n","transformer_encoder (None, 100, 1)\n","transformer_encoder (None, 100, 100)\n","after concat (None, 180)\n","transformer_encoder (None, 180, 1)\n","transformer_encoder (None, 180, 180)\n","Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_2 (InputLayer)           [(None, 100, 1)]     0           []                               \n","                                                                                                  \n"," input_3 (InputLayer)           [(None, 100, 1)]     0           []                               \n","                                                                                                  \n"," input_4 (InputLayer)           [(None, 100, 1)]     0           []                               \n","                                                                                                  \n"," input_5 (InputLayer)           [(None, 100, 1)]     0           []                               \n","                                                                                                  \n"," input_6 (InputLayer)           [(None, 100, 1)]     0           []                               \n","                                                                                                  \n"," input_7 (InputLayer)           [(None, 100, 1)]     0           []                               \n","                                                                                                  \n"," input_8 (InputLayer)           [(None, 100, 1)]     0           []                               \n","                                                                                                  \n"," input_9 (InputLayer)           [(None, 100, 1)]     0           []                               \n","                                                                                                  \n"," input_10 (InputLayer)          [(None, 100, 1)]     0           []                               \n","                                                                                                  \n"," input_11 (InputLayer)          [(None, 100, 1)]     0           []                               \n","                                                                                                  \n"," input_12 (InputLayer)          [(None, 100, 1)]     0           []                               \n","                                                                                                  \n"," input_13 (InputLayer)          [(None, 100, 1)]     0           []                               \n","                                                                                                  \n"," input_14 (InputLayer)          [(None, 100, 1)]     0           []                               \n","                                                                                                  \n"," input_15 (InputLayer)          [(None, 100, 1)]     0           []                               \n","                                                                                                  \n"," input_16 (InputLayer)          [(None, 100, 1)]     0           []                               \n","                                                                                                  \n"," input_17 (InputLayer)          [(None, 100, 1)]     0           []                               \n","                                                                                                  \n"," input_18 (InputLayer)          [(None, 100, 1)]     0           []                               \n","                                                                                                  \n"," input_1 (InputLayer)           [(None, 100, 1)]     0           []                               \n","                                                                                                  \n"," layer_normalization_4 (LayerNo  (None, 100, 1)      2           ['input_2[0][0]']                \n"," rmalization)                                                                                     \n","                                                                                                  \n"," layer_normalization_8 (LayerNo  (None, 100, 1)      2           ['input_3[0][0]']                \n"," rmalization)                                                                                     \n","                                                                                                  \n"," layer_normalization_12 (LayerN  (None, 100, 1)      2           ['input_4[0][0]']                \n"," ormalization)                                                                                    \n","                                                                                                  \n"," layer_normalization_16 (LayerN  (None, 100, 1)      2           ['input_5[0][0]']                \n"," ormalization)                                                                                    \n","                                                                                                  \n"," layer_normalization_20 (LayerN  (None, 100, 1)      2           ['input_6[0][0]']                \n"," ormalization)                                                                                    \n","                                                                                                  \n"," layer_normalization_24 (LayerN  (None, 100, 1)      2           ['input_7[0][0]']                \n"," ormalization)                                                                                    \n","                                                                                                  \n"," layer_normalization_28 (LayerN  (None, 100, 1)      2           ['input_8[0][0]']                \n"," ormalization)                                                                                    \n","                                                                                                  \n"," layer_normalization_32 (LayerN  (None, 100, 1)      2           ['input_9[0][0]']                \n"," ormalization)                                                                                    \n","                                                                                                  \n"," layer_normalization_36 (LayerN  (None, 100, 1)      2           ['input_10[0][0]']               \n"," ormalization)                                                                                    \n","                                                                                                  \n"," layer_normalization_40 (LayerN  (None, 100, 1)      2           ['input_11[0][0]']               \n"," ormalization)                                                                                    \n","                                                                                                  \n"," layer_normalization_44 (LayerN  (None, 100, 1)      2           ['input_12[0][0]']               \n"," ormalization)                                                                                    \n","                                                                                                  \n"," layer_normalization_48 (LayerN  (None, 100, 1)      2           ['input_13[0][0]']               \n"," ormalization)                                                                                    \n","                                                                                                  \n"," layer_normalization_52 (LayerN  (None, 100, 1)      2           ['input_14[0][0]']               \n"," ormalization)                                                                                    \n","                                                                                                  \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(RMSprop, self).__init__(name, **kwargs)\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":[" layer_normalization_56 (LayerN  (None, 100, 1)      2           ['input_15[0][0]']               \n"," ormalization)                                                                                    \n","                                                                                                  \n"," layer_normalization_60 (LayerN  (None, 100, 1)      2           ['input_16[0][0]']               \n"," ormalization)                                                                                    \n","                                                                                                  \n"," layer_normalization_64 (LayerN  (None, 100, 1)      2           ['input_17[0][0]']               \n"," ormalization)                                                                                    \n","                                                                                                  \n"," layer_normalization_68 (LayerN  (None, 100, 1)      2           ['input_18[0][0]']               \n"," ormalization)                                                                                    \n","                                                                                                  \n"," layer_normalization (LayerNorm  (None, 100, 1)      2           ['input_1[0][0]']                \n"," alization)                                                                                       \n","                                                                                                  \n"," multi_head_attention_2 (MultiH  (None, 100, 1)      1401        ['layer_normalization_4[0][0]',  \n"," eadAttention)                                                    'layer_normalization_4[0][0]']  \n","                                                                                                  \n"," multi_head_attention_4 (MultiH  (None, 100, 1)      1401        ['layer_normalization_8[0][0]',  \n"," eadAttention)                                                    'layer_normalization_8[0][0]']  \n","                                                                                                  \n"," multi_head_attention_6 (MultiH  (None, 100, 1)      1401        ['layer_normalization_12[0][0]', \n"," eadAttention)                                                    'layer_normalization_12[0][0]'] \n","                                                                                                  \n"," multi_head_attention_8 (MultiH  (None, 100, 1)      1401        ['layer_normalization_16[0][0]', \n"," eadAttention)                                                    'layer_normalization_16[0][0]'] \n","                                                                                                  \n"," multi_head_attention_10 (Multi  (None, 100, 1)      1401        ['layer_normalization_20[0][0]', \n"," HeadAttention)                                                   'layer_normalization_20[0][0]'] \n","                                                                                                  \n"," multi_head_attention_12 (Multi  (None, 100, 1)      1401        ['layer_normalization_24[0][0]', \n"," HeadAttention)                                                   'layer_normalization_24[0][0]'] \n","                                                                                                  \n"," multi_head_attention_14 (Multi  (None, 100, 1)      1401        ['layer_normalization_28[0][0]', \n"," HeadAttention)                                                   'layer_normalization_28[0][0]'] \n","                                                                                                  \n"," multi_head_attention_16 (Multi  (None, 100, 1)      1401        ['layer_normalization_32[0][0]', \n"," HeadAttention)                                                   'layer_normalization_32[0][0]'] \n","                                                                                                  \n"," multi_head_attention_18 (Multi  (None, 100, 1)      1401        ['layer_normalization_36[0][0]', \n"," HeadAttention)                                                   'layer_normalization_36[0][0]'] \n","                                                                                                  \n"," multi_head_attention_20 (Multi  (None, 100, 1)      1401        ['layer_normalization_40[0][0]', \n"," HeadAttention)                                                   'layer_normalization_40[0][0]'] \n","                                                                                                  \n"," multi_head_attention_22 (Multi  (None, 100, 1)      1401        ['layer_normalization_44[0][0]', \n"," HeadAttention)                                                   'layer_normalization_44[0][0]'] \n","                                                                                                  \n"," multi_head_attention_24 (Multi  (None, 100, 1)      1401        ['layer_normalization_48[0][0]', \n"," HeadAttention)                                                   'layer_normalization_48[0][0]'] \n","                                                                                                  \n"," multi_head_attention_26 (Multi  (None, 100, 1)      1401        ['layer_normalization_52[0][0]', \n"," HeadAttention)                                                   'layer_normalization_52[0][0]'] \n","                                                                                                  \n"," multi_head_attention_28 (Multi  (None, 100, 1)      1401        ['layer_normalization_56[0][0]', \n"," HeadAttention)                                                   'layer_normalization_56[0][0]'] \n","                                                                                                  \n"," multi_head_attention_30 (Multi  (None, 100, 1)      1401        ['layer_normalization_60[0][0]', \n"," HeadAttention)                                                   'layer_normalization_60[0][0]'] \n","                                                                                                  \n"," multi_head_attention_32 (Multi  (None, 100, 1)      1401        ['layer_normalization_64[0][0]', \n"," HeadAttention)                                                   'layer_normalization_64[0][0]'] \n","                                                                                                  \n"," multi_head_attention_34 (Multi  (None, 100, 1)      1401        ['layer_normalization_68[0][0]', \n"," HeadAttention)                                                   'layer_normalization_68[0][0]'] \n","                                                                                                  \n"," multi_head_attention (MultiHea  (None, 100, 1)      1401        ['layer_normalization[0][0]',    \n"," dAttention)                                                      'layer_normalization[0][0]']    \n","                                                                                                  \n"," dropout_2 (Dropout)            (None, 100, 1)       0           ['multi_head_attention_2[0][0]'] \n","                                                                                                  \n"," dropout_4 (Dropout)            (None, 100, 1)       0           ['multi_head_attention_4[0][0]'] \n","                                                                                                  \n"," dropout_6 (Dropout)            (None, 100, 1)       0           ['multi_head_attention_6[0][0]'] \n","                                                                                                  \n"," dropout_8 (Dropout)            (None, 100, 1)       0           ['multi_head_attention_8[0][0]'] \n","                                                                                                  \n"," dropout_10 (Dropout)           (None, 100, 1)       0           ['multi_head_attention_10[0][0]']\n","                                                                                                  \n"," dropout_12 (Dropout)           (None, 100, 1)       0           ['multi_head_attention_12[0][0]']\n","                                                                                                  \n"," dropout_14 (Dropout)           (None, 100, 1)       0           ['multi_head_attention_14[0][0]']\n","                                                                                                  \n"," dropout_16 (Dropout)           (None, 100, 1)       0           ['multi_head_attention_16[0][0]']\n","                                                                                                  \n"," dropout_18 (Dropout)           (None, 100, 1)       0           ['multi_head_attention_18[0][0]']\n","                                                                                                  \n"," dropout_20 (Dropout)           (None, 100, 1)       0           ['multi_head_attention_20[0][0]']\n","                                                                                                  \n"," dropout_22 (Dropout)           (None, 100, 1)       0           ['multi_head_attention_22[0][0]']\n","                                                                                                  \n"," dropout_24 (Dropout)           (None, 100, 1)       0           ['multi_head_attention_24[0][0]']\n","                                                                                                  \n"," dropout_26 (Dropout)           (None, 100, 1)       0           ['multi_head_attention_26[0][0]']\n","                                                                                                  \n"," dropout_28 (Dropout)           (None, 100, 1)       0           ['multi_head_attention_28[0][0]']\n","                                                                                                  \n"," dropout_30 (Dropout)           (None, 100, 1)       0           ['multi_head_attention_30[0][0]']\n","                                                                                                  \n"," dropout_32 (Dropout)           (None, 100, 1)       0           ['multi_head_attention_32[0][0]']\n","                                                                                                  \n"," dropout_34 (Dropout)           (None, 100, 1)       0           ['multi_head_attention_34[0][0]']\n","                                                                                                  \n"," dropout (Dropout)              (None, 100, 1)       0           ['multi_head_attention[0][0]']   \n","                                                                                                  \n"," tf.__operators__.add_4 (TFOpLa  (None, 100, 1)      0           ['dropout_2[0][0]',              \n"," mbda)                                                            'input_2[0][0]']                \n","                                                                                                  \n"," tf.__operators__.add_8 (TFOpLa  (None, 100, 1)      0           ['dropout_4[0][0]',              \n"," mbda)                                                            'input_3[0][0]']                \n","                                                                                                  \n"," tf.__operators__.add_12 (TFOpL  (None, 100, 1)      0           ['dropout_6[0][0]',              \n"," ambda)                                                           'input_4[0][0]']                \n","                                                                                                  \n"," tf.__operators__.add_16 (TFOpL  (None, 100, 1)      0           ['dropout_8[0][0]',              \n"," ambda)                                                           'input_5[0][0]']                \n","                                                                                                  \n"," tf.__operators__.add_20 (TFOpL  (None, 100, 1)      0           ['dropout_10[0][0]',             \n"," ambda)                                                           'input_6[0][0]']                \n","                                                                                                  \n"," tf.__operators__.add_24 (TFOpL  (None, 100, 1)      0           ['dropout_12[0][0]',             \n"," ambda)                                                           'input_7[0][0]']                \n","                                                                                                  \n"," tf.__operators__.add_28 (TFOpL  (None, 100, 1)      0           ['dropout_14[0][0]',             \n"," ambda)                                                           'input_8[0][0]']                \n","                                                                                                  \n"," tf.__operators__.add_32 (TFOpL  (None, 100, 1)      0           ['dropout_16[0][0]',             \n"," ambda)                                                           'input_9[0][0]']                \n","                                                                                                  \n"," tf.__operators__.add_36 (TFOpL  (None, 100, 1)      0           ['dropout_18[0][0]',             \n"," ambda)                                                           'input_10[0][0]']               \n","                                                                                                  \n"," tf.__operators__.add_40 (TFOpL  (None, 100, 1)      0           ['dropout_20[0][0]',             \n"," ambda)                                                           'input_11[0][0]']               \n","                                                                                                  \n"," tf.__operators__.add_44 (TFOpL  (None, 100, 1)      0           ['dropout_22[0][0]',             \n"," ambda)                                                           'input_12[0][0]']               \n","                                                                                                  \n"," tf.__operators__.add_48 (TFOpL  (None, 100, 1)      0           ['dropout_24[0][0]',             \n"," ambda)                                                           'input_13[0][0]']               \n","                                                                                                  \n"," tf.__operators__.add_52 (TFOpL  (None, 100, 1)      0           ['dropout_26[0][0]',             \n"," ambda)                                                           'input_14[0][0]']               \n","                                                                                                  \n"," tf.__operators__.add_56 (TFOpL  (None, 100, 1)      0           ['dropout_28[0][0]',             \n"," ambda)                                                           'input_15[0][0]']               \n","                                                                                                  \n"," tf.__operators__.add_60 (TFOpL  (None, 100, 1)      0           ['dropout_30[0][0]',             \n"," ambda)                                                           'input_16[0][0]']               \n","                                                                                                  \n"," tf.__operators__.add_64 (TFOpL  (None, 100, 1)      0           ['dropout_32[0][0]',             \n"," ambda)                                                           'input_17[0][0]']               \n","                                                                                                  \n"," tf.__operators__.add_68 (TFOpL  (None, 100, 1)      0           ['dropout_34[0][0]',             \n"," ambda)                                                           'input_18[0][0]']               \n","                                                                                                  \n"," tf.__operators__.add (TFOpLamb  (None, 100, 1)      0           ['dropout[0][0]',                \n"," da)                                                              'input_1[0][0]']                \n","                                                                                                  \n"," layer_normalization_5 (LayerNo  (None, 100, 1)      2           ['tf.__operators__.add_4[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," layer_normalization_9 (LayerNo  (None, 100, 1)      2           ['tf.__operators__.add_8[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," layer_normalization_13 (LayerN  (None, 100, 1)      2           ['tf.__operators__.add_12[0][0]']\n"," ormalization)                                                                                    \n","                                                                                                  \n"," layer_normalization_17 (LayerN  (None, 100, 1)      2           ['tf.__operators__.add_16[0][0]']\n"," ormalization)                                                                                    \n","                                                                                                  \n"," layer_normalization_21 (LayerN  (None, 100, 1)      2           ['tf.__operators__.add_20[0][0]']\n"," ormalization)                                                                                    \n","                                                                                                  \n"," layer_normalization_25 (LayerN  (None, 100, 1)      2           ['tf.__operators__.add_24[0][0]']\n"," ormalization)                                                                                    \n","                                                                                                  \n"," layer_normalization_29 (LayerN  (None, 100, 1)      2           ['tf.__operators__.add_28[0][0]']\n"," ormalization)                                                                                    \n","                                                                                                  \n"," layer_normalization_33 (LayerN  (None, 100, 1)      2           ['tf.__operators__.add_32[0][0]']\n"," ormalization)                                                                                    \n","                                                                                                  \n"," layer_normalization_37 (LayerN  (None, 100, 1)      2           ['tf.__operators__.add_36[0][0]']\n"," ormalization)                                                                                    \n","                                                                                                  \n"," layer_normalization_41 (LayerN  (None, 100, 1)      2           ['tf.__operators__.add_40[0][0]']\n"," ormalization)                                                                                    \n","                                                                                                  \n"," layer_normalization_45 (LayerN  (None, 100, 1)      2           ['tf.__operators__.add_44[0][0]']\n"," ormalization)                                                                                    \n","                                                                                                  \n"," layer_normalization_49 (LayerN  (None, 100, 1)      2           ['tf.__operators__.add_48[0][0]']\n"," ormalization)                                                                                    \n","                                                                                                  \n"," layer_normalization_53 (LayerN  (None, 100, 1)      2           ['tf.__operators__.add_52[0][0]']\n"," ormalization)                                                                                    \n","                                                                                                  \n"," layer_normalization_57 (LayerN  (None, 100, 1)      2           ['tf.__operators__.add_56[0][0]']\n"," ormalization)                                                                                    \n","                                                                                                  \n"," layer_normalization_61 (LayerN  (None, 100, 1)      2           ['tf.__operators__.add_60[0][0]']\n"," ormalization)                                                                                    \n","                                                                                                  \n"," layer_normalization_65 (LayerN  (None, 100, 1)      2           ['tf.__operators__.add_64[0][0]']\n"," ormalization)                                                                                    \n","                                                                                                  \n"," layer_normalization_69 (LayerN  (None, 100, 1)      2           ['tf.__operators__.add_68[0][0]']\n"," ormalization)                                                                                    \n","                                                                                                  \n"," layer_normalization_1 (LayerNo  (None, 100, 1)      2           ['tf.__operators__.add[0][0]']   \n"," rmalization)                                                                                     \n","                                                                                                  \n"," dense_3 (Dense)                (None, 100, 100)     200         ['layer_normalization_5[0][0]']  \n","                                                                                                  \n"," dense_6 (Dense)                (None, 100, 100)     200         ['layer_normalization_9[0][0]']  \n","                                                                                                  \n"," dense_9 (Dense)                (None, 100, 100)     200         ['layer_normalization_13[0][0]'] \n","                                                                                                  \n"," dense_12 (Dense)               (None, 100, 100)     200         ['layer_normalization_17[0][0]'] \n","                                                                                                  \n"," dense_15 (Dense)               (None, 100, 100)     200         ['layer_normalization_21[0][0]'] \n","                                                                                                  \n"," dense_18 (Dense)               (None, 100, 100)     200         ['layer_normalization_25[0][0]'] \n","                                                                                                  \n"," dense_21 (Dense)               (None, 100, 100)     200         ['layer_normalization_29[0][0]'] \n","                                                                                                  \n"," dense_24 (Dense)               (None, 100, 100)     200         ['layer_normalization_33[0][0]'] \n","                                                                                                  \n"," dense_27 (Dense)               (None, 100, 100)     200         ['layer_normalization_37[0][0]'] \n","                                                                                                  \n"," dense_30 (Dense)               (None, 100, 100)     200         ['layer_normalization_41[0][0]'] \n","                                                                                                  \n"," dense_33 (Dense)               (None, 100, 100)     200         ['layer_normalization_45[0][0]'] \n","                                                                                                  \n"," dense_36 (Dense)               (None, 100, 100)     200         ['layer_normalization_49[0][0]'] \n","                                                                                                  \n"," dense_39 (Dense)               (None, 100, 100)     200         ['layer_normalization_53[0][0]'] \n","                                                                                                  \n"," dense_42 (Dense)               (None, 100, 100)     200         ['layer_normalization_57[0][0]'] \n","                                                                                                  \n"," dense_45 (Dense)               (None, 100, 100)     200         ['layer_normalization_61[0][0]'] \n","                                                                                                  \n"," dense_48 (Dense)               (None, 100, 100)     200         ['layer_normalization_65[0][0]'] \n","                                                                                                  \n"," dense_51 (Dense)               (None, 100, 100)     200         ['layer_normalization_69[0][0]'] \n","                                                                                                  \n"," dense (Dense)                  (None, 100, 100)     200         ['layer_normalization_1[0][0]']  \n","                                                                                                  \n"," tf.__operators__.add_5 (TFOpLa  (None, 100, 100)    0           ['dense_3[0][0]',                \n"," mbda)                                                            'tf.__operators__.add_4[0][0]'] \n","                                                                                                  \n"," tf.__operators__.add_9 (TFOpLa  (None, 100, 100)    0           ['dense_6[0][0]',                \n"," mbda)                                                            'tf.__operators__.add_8[0][0]'] \n","                                                                                                  \n"," tf.__operators__.add_13 (TFOpL  (None, 100, 100)    0           ['dense_9[0][0]',                \n"," ambda)                                                           'tf.__operators__.add_12[0][0]']\n","                                                                                                  \n"," tf.__operators__.add_17 (TFOpL  (None, 100, 100)    0           ['dense_12[0][0]',               \n"," ambda)                                                           'tf.__operators__.add_16[0][0]']\n","                                                                                                  \n"," tf.__operators__.add_21 (TFOpL  (None, 100, 100)    0           ['dense_15[0][0]',               \n"," ambda)                                                           'tf.__operators__.add_20[0][0]']\n","                                                                                                  \n"," tf.__operators__.add_25 (TFOpL  (None, 100, 100)    0           ['dense_18[0][0]',               \n"," ambda)                                                           'tf.__operators__.add_24[0][0]']\n","                                                                                                  \n"," tf.__operators__.add_29 (TFOpL  (None, 100, 100)    0           ['dense_21[0][0]',               \n"," ambda)                                                           'tf.__operators__.add_28[0][0]']\n","                                                                                                  \n"," tf.__operators__.add_33 (TFOpL  (None, 100, 100)    0           ['dense_24[0][0]',               \n"," ambda)                                                           'tf.__operators__.add_32[0][0]']\n","                                                                                                  \n"," tf.__operators__.add_37 (TFOpL  (None, 100, 100)    0           ['dense_27[0][0]',               \n"," ambda)                                                           'tf.__operators__.add_36[0][0]']\n","                                                                                                  \n"," tf.__operators__.add_41 (TFOpL  (None, 100, 100)    0           ['dense_30[0][0]',               \n"," ambda)                                                           'tf.__operators__.add_40[0][0]']\n","                                                                                                  \n"," tf.__operators__.add_45 (TFOpL  (None, 100, 100)    0           ['dense_33[0][0]',               \n"," ambda)                                                           'tf.__operators__.add_44[0][0]']\n","                                                                                                  \n"," tf.__operators__.add_49 (TFOpL  (None, 100, 100)    0           ['dense_36[0][0]',               \n"," ambda)                                                           'tf.__operators__.add_48[0][0]']\n","                                                                                                  \n"," tf.__operators__.add_53 (TFOpL  (None, 100, 100)    0           ['dense_39[0][0]',               \n"," ambda)                                                           'tf.__operators__.add_52[0][0]']\n","                                                                                                  \n"," tf.__operators__.add_57 (TFOpL  (None, 100, 100)    0           ['dense_42[0][0]',               \n"," ambda)                                                           'tf.__operators__.add_56[0][0]']\n","                                                                                                  \n"," tf.__operators__.add_61 (TFOpL  (None, 100, 100)    0           ['dense_45[0][0]',               \n"," ambda)                                                           'tf.__operators__.add_60[0][0]']\n","                                                                                                  \n"," tf.__operators__.add_65 (TFOpL  (None, 100, 100)    0           ['dense_48[0][0]',               \n"," ambda)                                                           'tf.__operators__.add_64[0][0]']\n","                                                                                                  \n"," tf.__operators__.add_69 (TFOpL  (None, 100, 100)    0           ['dense_51[0][0]',               \n"," ambda)                                                           'tf.__operators__.add_68[0][0]']\n","                                                                                                  \n"," tf.__operators__.add_1 (TFOpLa  (None, 100, 100)    0           ['dense[0][0]',                  \n"," mbda)                                                            'tf.__operators__.add[0][0]']   \n","                                                                                                  \n"," layer_normalization_6 (LayerNo  (None, 100, 100)    200         ['tf.__operators__.add_5[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," layer_normalization_10 (LayerN  (None, 100, 100)    200         ['tf.__operators__.add_9[0][0]'] \n"," ormalization)                                                                                    \n","                                                                                                  \n"," layer_normalization_14 (LayerN  (None, 100, 100)    200         ['tf.__operators__.add_13[0][0]']\n"," ormalization)                                                                                    \n","                                                                                                  \n"," layer_normalization_18 (LayerN  (None, 100, 100)    200         ['tf.__operators__.add_17[0][0]']\n"," ormalization)                                                                                    \n","                                                                                                  \n"," layer_normalization_22 (LayerN  (None, 100, 100)    200         ['tf.__operators__.add_21[0][0]']\n"," ormalization)                                                                                    \n","                                                                                                  \n"," layer_normalization_26 (LayerN  (None, 100, 100)    200         ['tf.__operators__.add_25[0][0]']\n"," ormalization)                                                                                    \n","                                                                                                  \n"," layer_normalization_30 (LayerN  (None, 100, 100)    200         ['tf.__operators__.add_29[0][0]']\n"," ormalization)                                                                                    \n","                                                                                                  \n"," layer_normalization_34 (LayerN  (None, 100, 100)    200         ['tf.__operators__.add_33[0][0]']\n"," ormalization)                                                                                    \n","                                                                                                  \n"," layer_normalization_38 (LayerN  (None, 100, 100)    200         ['tf.__operators__.add_37[0][0]']\n"," ormalization)                                                                                    \n","                                                                                                  \n"," layer_normalization_42 (LayerN  (None, 100, 100)    200         ['tf.__operators__.add_41[0][0]']\n"," ormalization)                                                                                    \n","                                                                                                  \n"," layer_normalization_46 (LayerN  (None, 100, 100)    200         ['tf.__operators__.add_45[0][0]']\n"," ormalization)                                                                                    \n","                                                                                                  \n"," layer_normalization_50 (LayerN  (None, 100, 100)    200         ['tf.__operators__.add_49[0][0]']\n"," ormalization)                                                                                    \n","                                                                                                  \n"," layer_normalization_54 (LayerN  (None, 100, 100)    200         ['tf.__operators__.add_53[0][0]']\n"," ormalization)                                                                                    \n","                                                                                                  \n"," layer_normalization_58 (LayerN  (None, 100, 100)    200         ['tf.__operators__.add_57[0][0]']\n"," ormalization)                                                                                    \n","                                                                                                  \n"," layer_normalization_62 (LayerN  (None, 100, 100)    200         ['tf.__operators__.add_61[0][0]']\n"," ormalization)                                                                                    \n","                                                                                                  \n"," layer_normalization_66 (LayerN  (None, 100, 100)    200         ['tf.__operators__.add_65[0][0]']\n"," ormalization)                                                                                    \n","                                                                                                  \n"," layer_normalization_70 (LayerN  (None, 100, 100)    200         ['tf.__operators__.add_69[0][0]']\n"," ormalization)                                                                                    \n","                                                                                                  \n"," layer_normalization_2 (LayerNo  (None, 100, 100)    200         ['tf.__operators__.add_1[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," multi_head_attention_3 (MultiH  (None, 100, 100)    80700       ['layer_normalization_6[0][0]',  \n"," eadAttention)                                                    'layer_normalization_6[0][0]']  \n","                                                                                                  \n"," multi_head_attention_5 (MultiH  (None, 100, 100)    80700       ['layer_normalization_10[0][0]', \n"," eadAttention)                                                    'layer_normalization_10[0][0]'] \n","                                                                                                  \n"," multi_head_attention_7 (MultiH  (None, 100, 100)    80700       ['layer_normalization_14[0][0]', \n"," eadAttention)                                                    'layer_normalization_14[0][0]'] \n","                                                                                                  \n"," multi_head_attention_9 (MultiH  (None, 100, 100)    80700       ['layer_normalization_18[0][0]', \n"," eadAttention)                                                    'layer_normalization_18[0][0]'] \n","                                                                                                  \n"," multi_head_attention_11 (Multi  (None, 100, 100)    80700       ['layer_normalization_22[0][0]', \n"," HeadAttention)                                                   'layer_normalization_22[0][0]'] \n","                                                                                                  \n"," multi_head_attention_13 (Multi  (None, 100, 100)    80700       ['layer_normalization_26[0][0]', \n"," HeadAttention)                                                   'layer_normalization_26[0][0]'] \n","                                                                                                  \n"," multi_head_attention_15 (Multi  (None, 100, 100)    80700       ['layer_normalization_30[0][0]', \n"," HeadAttention)                                                   'layer_normalization_30[0][0]'] \n","                                                                                                  \n"," multi_head_attention_17 (Multi  (None, 100, 100)    80700       ['layer_normalization_34[0][0]', \n"," HeadAttention)                                                   'layer_normalization_34[0][0]'] \n","                                                                                                  \n"," multi_head_attention_19 (Multi  (None, 100, 100)    80700       ['layer_normalization_38[0][0]', \n"," HeadAttention)                                                   'layer_normalization_38[0][0]'] \n","                                                                                                  \n"," multi_head_attention_21 (Multi  (None, 100, 100)    80700       ['layer_normalization_42[0][0]', \n"," HeadAttention)                                                   'layer_normalization_42[0][0]'] \n","                                                                                                  \n"," multi_head_attention_23 (Multi  (None, 100, 100)    80700       ['layer_normalization_46[0][0]', \n"," HeadAttention)                                                   'layer_normalization_46[0][0]'] \n","                                                                                                  \n"," multi_head_attention_25 (Multi  (None, 100, 100)    80700       ['layer_normalization_50[0][0]', \n"," HeadAttention)                                                   'layer_normalization_50[0][0]'] \n","                                                                                                  \n"," multi_head_attention_27 (Multi  (None, 100, 100)    80700       ['layer_normalization_54[0][0]', \n"," HeadAttention)                                                   'layer_normalization_54[0][0]'] \n","                                                                                                  \n"," multi_head_attention_29 (Multi  (None, 100, 100)    80700       ['layer_normalization_58[0][0]', \n"," HeadAttention)                                                   'layer_normalization_58[0][0]'] \n","                                                                                                  \n"," multi_head_attention_31 (Multi  (None, 100, 100)    80700       ['layer_normalization_62[0][0]', \n"," HeadAttention)                                                   'layer_normalization_62[0][0]'] \n","                                                                                                  \n"," multi_head_attention_33 (Multi  (None, 100, 100)    80700       ['layer_normalization_66[0][0]', \n"," HeadAttention)                                                   'layer_normalization_66[0][0]'] \n","                                                                                                  \n"," multi_head_attention_35 (Multi  (None, 100, 100)    80700       ['layer_normalization_70[0][0]', \n"," HeadAttention)                                                   'layer_normalization_70[0][0]'] \n","                                                                                                  \n"," multi_head_attention_1 (MultiH  (None, 100, 100)    80700       ['layer_normalization_2[0][0]',  \n"," eadAttention)                                                    'layer_normalization_2[0][0]']  \n","                                                                                                  \n"," dropout_3 (Dropout)            (None, 100, 100)     0           ['multi_head_attention_3[0][0]'] \n","                                                                                                  \n"," dropout_5 (Dropout)            (None, 100, 100)     0           ['multi_head_attention_5[0][0]'] \n","                                                                                                  \n"," dropout_7 (Dropout)            (None, 100, 100)     0           ['multi_head_attention_7[0][0]'] \n","                                                                                                  \n"," dropout_9 (Dropout)            (None, 100, 100)     0           ['multi_head_attention_9[0][0]'] \n","                                                                                                  \n"," dropout_11 (Dropout)           (None, 100, 100)     0           ['multi_head_attention_11[0][0]']\n","                                                                                                  \n"," dropout_13 (Dropout)           (None, 100, 100)     0           ['multi_head_attention_13[0][0]']\n","                                                                                                  \n"," dropout_15 (Dropout)           (None, 100, 100)     0           ['multi_head_attention_15[0][0]']\n","                                                                                                  \n"," dropout_17 (Dropout)           (None, 100, 100)     0           ['multi_head_attention_17[0][0]']\n","                                                                                                  \n"," dropout_19 (Dropout)           (None, 100, 100)     0           ['multi_head_attention_19[0][0]']\n","                                                                                                  \n"," dropout_21 (Dropout)           (None, 100, 100)     0           ['multi_head_attention_21[0][0]']\n","                                                                                                  \n"," dropout_23 (Dropout)           (None, 100, 100)     0           ['multi_head_attention_23[0][0]']\n","                                                                                                  \n"," dropout_25 (Dropout)           (None, 100, 100)     0           ['multi_head_attention_25[0][0]']\n","                                                                                                  \n"," dropout_27 (Dropout)           (None, 100, 100)     0           ['multi_head_attention_27[0][0]']\n","                                                                                                  \n"," dropout_29 (Dropout)           (None, 100, 100)     0           ['multi_head_attention_29[0][0]']\n","                                                                                                  \n"," dropout_31 (Dropout)           (None, 100, 100)     0           ['multi_head_attention_31[0][0]']\n","                                                                                                  \n"," dropout_33 (Dropout)           (None, 100, 100)     0           ['multi_head_attention_33[0][0]']\n","                                                                                                  \n"," dropout_35 (Dropout)           (None, 100, 100)     0           ['multi_head_attention_35[0][0]']\n","                                                                                                  \n"," dropout_1 (Dropout)            (None, 100, 100)     0           ['multi_head_attention_1[0][0]'] \n","                                                                                                  \n"," tf.__operators__.add_6 (TFOpLa  (None, 100, 100)    0           ['dropout_3[0][0]',              \n"," mbda)                                                            'tf.__operators__.add_5[0][0]'] \n","                                                                                                  \n"," tf.__operators__.add_10 (TFOpL  (None, 100, 100)    0           ['dropout_5[0][0]',              \n"," ambda)                                                           'tf.__operators__.add_9[0][0]'] \n","                                                                                                  \n"," tf.__operators__.add_14 (TFOpL  (None, 100, 100)    0           ['dropout_7[0][0]',              \n"," ambda)                                                           'tf.__operators__.add_13[0][0]']\n","                                                                                                  \n"," tf.__operators__.add_18 (TFOpL  (None, 100, 100)    0           ['dropout_9[0][0]',              \n"," ambda)                                                           'tf.__operators__.add_17[0][0]']\n","                                                                                                  \n"," tf.__operators__.add_22 (TFOpL  (None, 100, 100)    0           ['dropout_11[0][0]',             \n"," ambda)                                                           'tf.__operators__.add_21[0][0]']\n","                                                                                                  \n"," tf.__operators__.add_26 (TFOpL  (None, 100, 100)    0           ['dropout_13[0][0]',             \n"," ambda)                                                           'tf.__operators__.add_25[0][0]']\n","                                                                                                  \n"," tf.__operators__.add_30 (TFOpL  (None, 100, 100)    0           ['dropout_15[0][0]',             \n"," ambda)                                                           'tf.__operators__.add_29[0][0]']\n","                                                                                                  \n"," tf.__operators__.add_34 (TFOpL  (None, 100, 100)    0           ['dropout_17[0][0]',             \n"," ambda)                                                           'tf.__operators__.add_33[0][0]']\n","                                                                                                  \n"," tf.__operators__.add_38 (TFOpL  (None, 100, 100)    0           ['dropout_19[0][0]',             \n"," ambda)                                                           'tf.__operators__.add_37[0][0]']\n","                                                                                                  \n"," tf.__operators__.add_42 (TFOpL  (None, 100, 100)    0           ['dropout_21[0][0]',             \n"," ambda)                                                           'tf.__operators__.add_41[0][0]']\n","                                                                                                  \n"," tf.__operators__.add_46 (TFOpL  (None, 100, 100)    0           ['dropout_23[0][0]',             \n"," ambda)                                                           'tf.__operators__.add_45[0][0]']\n","                                                                                                  \n"," tf.__operators__.add_50 (TFOpL  (None, 100, 100)    0           ['dropout_25[0][0]',             \n"," ambda)                                                           'tf.__operators__.add_49[0][0]']\n","                                                                                                  \n"," tf.__operators__.add_54 (TFOpL  (None, 100, 100)    0           ['dropout_27[0][0]',             \n"," ambda)                                                           'tf.__operators__.add_53[0][0]']\n","                                                                                                  \n"," tf.__operators__.add_58 (TFOpL  (None, 100, 100)    0           ['dropout_29[0][0]',             \n"," ambda)                                                           'tf.__operators__.add_57[0][0]']\n","                                                                                                  \n"," tf.__operators__.add_62 (TFOpL  (None, 100, 100)    0           ['dropout_31[0][0]',             \n"," ambda)                                                           'tf.__operators__.add_61[0][0]']\n","                                                                                                  \n"," tf.__operators__.add_66 (TFOpL  (None, 100, 100)    0           ['dropout_33[0][0]',             \n"," ambda)                                                           'tf.__operators__.add_65[0][0]']\n","                                                                                                  \n"," tf.__operators__.add_70 (TFOpL  (None, 100, 100)    0           ['dropout_35[0][0]',             \n"," ambda)                                                           'tf.__operators__.add_69[0][0]']\n","                                                                                                  \n"," tf.__operators__.add_2 (TFOpLa  (None, 100, 100)    0           ['dropout_1[0][0]',              \n"," mbda)                                                            'tf.__operators__.add_1[0][0]'] \n","                                                                                                  \n"," layer_normalization_7 (LayerNo  (None, 100, 100)    200         ['tf.__operators__.add_6[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," layer_normalization_11 (LayerN  (None, 100, 100)    200         ['tf.__operators__.add_10[0][0]']\n"," ormalization)                                                                                    \n","                                                                                                  \n"," layer_normalization_15 (LayerN  (None, 100, 100)    200         ['tf.__operators__.add_14[0][0]']\n"," ormalization)                                                                                    \n","                                                                                                  \n"," layer_normalization_19 (LayerN  (None, 100, 100)    200         ['tf.__operators__.add_18[0][0]']\n"," ormalization)                                                                                    \n","                                                                                                  \n"," layer_normalization_23 (LayerN  (None, 100, 100)    200         ['tf.__operators__.add_22[0][0]']\n"," ormalization)                                                                                    \n","                                                                                                  \n"," layer_normalization_27 (LayerN  (None, 100, 100)    200         ['tf.__operators__.add_26[0][0]']\n"," ormalization)                                                                                    \n","                                                                                                  \n"," layer_normalization_31 (LayerN  (None, 100, 100)    200         ['tf.__operators__.add_30[0][0]']\n"," ormalization)                                                                                    \n","                                                                                                  \n"," layer_normalization_35 (LayerN  (None, 100, 100)    200         ['tf.__operators__.add_34[0][0]']\n"," ormalization)                                                                                    \n","                                                                                                  \n"," layer_normalization_39 (LayerN  (None, 100, 100)    200         ['tf.__operators__.add_38[0][0]']\n"," ormalization)                                                                                    \n","                                                                                                  \n"," layer_normalization_43 (LayerN  (None, 100, 100)    200         ['tf.__operators__.add_42[0][0]']\n"," ormalization)                                                                                    \n","                                                                                                  \n"," layer_normalization_47 (LayerN  (None, 100, 100)    200         ['tf.__operators__.add_46[0][0]']\n"," ormalization)                                                                                    \n","                                                                                                  \n"," layer_normalization_51 (LayerN  (None, 100, 100)    200         ['tf.__operators__.add_50[0][0]']\n"," ormalization)                                                                                    \n","                                                                                                  \n"," layer_normalization_55 (LayerN  (None, 100, 100)    200         ['tf.__operators__.add_54[0][0]']\n"," ormalization)                                                                                    \n","                                                                                                  \n"," layer_normalization_59 (LayerN  (None, 100, 100)    200         ['tf.__operators__.add_58[0][0]']\n"," ormalization)                                                                                    \n","                                                                                                  \n"," layer_normalization_63 (LayerN  (None, 100, 100)    200         ['tf.__operators__.add_62[0][0]']\n"," ormalization)                                                                                    \n","                                                                                                  \n"," layer_normalization_67 (LayerN  (None, 100, 100)    200         ['tf.__operators__.add_66[0][0]']\n"," ormalization)                                                                                    \n","                                                                                                  \n"," layer_normalization_71 (LayerN  (None, 100, 100)    200         ['tf.__operators__.add_70[0][0]']\n"," ormalization)                                                                                    \n","                                                                                                  \n"," layer_normalization_3 (LayerNo  (None, 100, 100)    200         ['tf.__operators__.add_2[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," dense_4 (Dense)                (None, 100, 100)     10100       ['layer_normalization_7[0][0]']  \n","                                                                                                  \n"," dense_7 (Dense)                (None, 100, 100)     10100       ['layer_normalization_11[0][0]'] \n","                                                                                                  \n"," dense_10 (Dense)               (None, 100, 100)     10100       ['layer_normalization_15[0][0]'] \n","                                                                                                  \n"," dense_13 (Dense)               (None, 100, 100)     10100       ['layer_normalization_19[0][0]'] \n","                                                                                                  \n"," dense_16 (Dense)               (None, 100, 100)     10100       ['layer_normalization_23[0][0]'] \n","                                                                                                  \n"," dense_19 (Dense)               (None, 100, 100)     10100       ['layer_normalization_27[0][0]'] \n","                                                                                                  \n"," dense_22 (Dense)               (None, 100, 100)     10100       ['layer_normalization_31[0][0]'] \n","                                                                                                  \n"," dense_25 (Dense)               (None, 100, 100)     10100       ['layer_normalization_35[0][0]'] \n","                                                                                                  \n"," dense_28 (Dense)               (None, 100, 100)     10100       ['layer_normalization_39[0][0]'] \n","                                                                                                  \n"," dense_31 (Dense)               (None, 100, 100)     10100       ['layer_normalization_43[0][0]'] \n","                                                                                                  \n"," dense_34 (Dense)               (None, 100, 100)     10100       ['layer_normalization_47[0][0]'] \n","                                                                                                  \n"," dense_37 (Dense)               (None, 100, 100)     10100       ['layer_normalization_51[0][0]'] \n","                                                                                                  \n"," dense_40 (Dense)               (None, 100, 100)     10100       ['layer_normalization_55[0][0]'] \n","                                                                                                  \n"," dense_43 (Dense)               (None, 100, 100)     10100       ['layer_normalization_59[0][0]'] \n","                                                                                                  \n"," dense_46 (Dense)               (None, 100, 100)     10100       ['layer_normalization_63[0][0]'] \n","                                                                                                  \n"," dense_49 (Dense)               (None, 100, 100)     10100       ['layer_normalization_67[0][0]'] \n","                                                                                                  \n"," dense_52 (Dense)               (None, 100, 100)     10100       ['layer_normalization_71[0][0]'] \n","                                                                                                  \n"," dense_1 (Dense)                (None, 100, 100)     10100       ['layer_normalization_3[0][0]']  \n","                                                                                                  \n"," tf.__operators__.add_7 (TFOpLa  (None, 100, 100)    0           ['dense_4[0][0]',                \n"," mbda)                                                            'tf.__operators__.add_6[0][0]'] \n","                                                                                                  \n"," tf.__operators__.add_11 (TFOpL  (None, 100, 100)    0           ['dense_7[0][0]',                \n"," ambda)                                                           'tf.__operators__.add_10[0][0]']\n","                                                                                                  \n"," tf.__operators__.add_15 (TFOpL  (None, 100, 100)    0           ['dense_10[0][0]',               \n"," ambda)                                                           'tf.__operators__.add_14[0][0]']\n","                                                                                                  \n"," tf.__operators__.add_19 (TFOpL  (None, 100, 100)    0           ['dense_13[0][0]',               \n"," ambda)                                                           'tf.__operators__.add_18[0][0]']\n","                                                                                                  \n"," tf.__operators__.add_23 (TFOpL  (None, 100, 100)    0           ['dense_16[0][0]',               \n"," ambda)                                                           'tf.__operators__.add_22[0][0]']\n","                                                                                                  \n"," tf.__operators__.add_27 (TFOpL  (None, 100, 100)    0           ['dense_19[0][0]',               \n"," ambda)                                                           'tf.__operators__.add_26[0][0]']\n","                                                                                                  \n"," tf.__operators__.add_31 (TFOpL  (None, 100, 100)    0           ['dense_22[0][0]',               \n"," ambda)                                                           'tf.__operators__.add_30[0][0]']\n","                                                                                                  \n"," tf.__operators__.add_35 (TFOpL  (None, 100, 100)    0           ['dense_25[0][0]',               \n"," ambda)                                                           'tf.__operators__.add_34[0][0]']\n","                                                                                                  \n"," tf.__operators__.add_39 (TFOpL  (None, 100, 100)    0           ['dense_28[0][0]',               \n"," ambda)                                                           'tf.__operators__.add_38[0][0]']\n","                                                                                                  \n"," tf.__operators__.add_43 (TFOpL  (None, 100, 100)    0           ['dense_31[0][0]',               \n"," ambda)                                                           'tf.__operators__.add_42[0][0]']\n","                                                                                                  \n"," tf.__operators__.add_47 (TFOpL  (None, 100, 100)    0           ['dense_34[0][0]',               \n"," ambda)                                                           'tf.__operators__.add_46[0][0]']\n","                                                                                                  \n"," tf.__operators__.add_51 (TFOpL  (None, 100, 100)    0           ['dense_37[0][0]',               \n"," ambda)                                                           'tf.__operators__.add_50[0][0]']\n","                                                                                                  \n"," tf.__operators__.add_55 (TFOpL  (None, 100, 100)    0           ['dense_40[0][0]',               \n"," ambda)                                                           'tf.__operators__.add_54[0][0]']\n","                                                                                                  \n"," tf.__operators__.add_59 (TFOpL  (None, 100, 100)    0           ['dense_43[0][0]',               \n"," ambda)                                                           'tf.__operators__.add_58[0][0]']\n","                                                                                                  \n"," tf.__operators__.add_63 (TFOpL  (None, 100, 100)    0           ['dense_46[0][0]',               \n"," ambda)                                                           'tf.__operators__.add_62[0][0]']\n","                                                                                                  \n"," tf.__operators__.add_67 (TFOpL  (None, 100, 100)    0           ['dense_49[0][0]',               \n"," ambda)                                                           'tf.__operators__.add_66[0][0]']\n","                                                                                                  \n"," tf.__operators__.add_71 (TFOpL  (None, 100, 100)    0           ['dense_52[0][0]',               \n"," ambda)                                                           'tf.__operators__.add_70[0][0]']\n","                                                                                                  \n"," tf.__operators__.add_3 (TFOpLa  (None, 100, 100)    0           ['dense_1[0][0]',                \n"," mbda)                                                            'tf.__operators__.add_2[0][0]'] \n","                                                                                                  \n"," global_average_pooling1d_1 (Gl  (None, 100)         0           ['tf.__operators__.add_7[0][0]'] \n"," obalAveragePooling1D)                                                                            \n","                                                                                                  \n"," global_average_pooling1d_2 (Gl  (None, 100)         0           ['tf.__operators__.add_11[0][0]']\n"," obalAveragePooling1D)                                                                            \n","                                                                                                  \n"," global_average_pooling1d_3 (Gl  (None, 100)         0           ['tf.__operators__.add_15[0][0]']\n"," obalAveragePooling1D)                                                                            \n","                                                                                                  \n"," global_average_pooling1d_4 (Gl  (None, 100)         0           ['tf.__operators__.add_19[0][0]']\n"," obalAveragePooling1D)                                                                            \n","                                                                                                  \n"," global_average_pooling1d_5 (Gl  (None, 100)         0           ['tf.__operators__.add_23[0][0]']\n"," obalAveragePooling1D)                                                                            \n","                                                                                                  \n"," global_average_pooling1d_6 (Gl  (None, 100)         0           ['tf.__operators__.add_27[0][0]']\n"," obalAveragePooling1D)                                                                            \n","                                                                                                  \n"," global_average_pooling1d_7 (Gl  (None, 100)         0           ['tf.__operators__.add_31[0][0]']\n"," obalAveragePooling1D)                                                                            \n","                                                                                                  \n"," global_average_pooling1d_8 (Gl  (None, 100)         0           ['tf.__operators__.add_35[0][0]']\n"," obalAveragePooling1D)                                                                            \n","                                                                                                  \n"," global_average_pooling1d_9 (Gl  (None, 100)         0           ['tf.__operators__.add_39[0][0]']\n"," obalAveragePooling1D)                                                                            \n","                                                                                                  \n"," global_average_pooling1d_10 (G  (None, 100)         0           ['tf.__operators__.add_43[0][0]']\n"," lobalAveragePooling1D)                                                                           \n","                                                                                                  \n"," global_average_pooling1d_11 (G  (None, 100)         0           ['tf.__operators__.add_47[0][0]']\n"," lobalAveragePooling1D)                                                                           \n","                                                                                                  \n"," global_average_pooling1d_12 (G  (None, 100)         0           ['tf.__operators__.add_51[0][0]']\n"," lobalAveragePooling1D)                                                                           \n","                                                                                                  \n"," global_average_pooling1d_13 (G  (None, 100)         0           ['tf.__operators__.add_55[0][0]']\n"," lobalAveragePooling1D)                                                                           \n","                                                                                                  \n"," global_average_pooling1d_14 (G  (None, 100)         0           ['tf.__operators__.add_59[0][0]']\n"," lobalAveragePooling1D)                                                                           \n","                                                                                                  \n"," global_average_pooling1d_15 (G  (None, 100)         0           ['tf.__operators__.add_63[0][0]']\n"," lobalAveragePooling1D)                                                                           \n","                                                                                                  \n"," global_average_pooling1d_16 (G  (None, 100)         0           ['tf.__operators__.add_67[0][0]']\n"," lobalAveragePooling1D)                                                                           \n","                                                                                                  \n"," global_average_pooling1d_17 (G  (None, 100)         0           ['tf.__operators__.add_71[0][0]']\n"," lobalAveragePooling1D)                                                                           \n","                                                                                                  \n"," global_average_pooling1d (Glob  (None, 100)         0           ['tf.__operators__.add_3[0][0]'] \n"," alAveragePooling1D)                                                                              \n","                                                                                                  \n"," dense_5 (Dense)                (None, 10)           1010        ['global_average_pooling1d_1[0][0\n","                                                                 ]']                              \n","                                                                                                  \n"," dense_8 (Dense)                (None, 10)           1010        ['global_average_pooling1d_2[0][0\n","                                                                 ]']                              \n","                                                                                                  \n"," dense_11 (Dense)               (None, 10)           1010        ['global_average_pooling1d_3[0][0\n","                                                                 ]']                              \n","                                                                                                  \n"," dense_14 (Dense)               (None, 10)           1010        ['global_average_pooling1d_4[0][0\n","                                                                 ]']                              \n","                                                                                                  \n"," dense_17 (Dense)               (None, 10)           1010        ['global_average_pooling1d_5[0][0\n","                                                                 ]']                              \n","                                                                                                  \n"," dense_20 (Dense)               (None, 10)           1010        ['global_average_pooling1d_6[0][0\n","                                                                 ]']                              \n","                                                                                                  \n"," dense_23 (Dense)               (None, 10)           1010        ['global_average_pooling1d_7[0][0\n","                                                                 ]']                              \n","                                                                                                  \n"," dense_26 (Dense)               (None, 10)           1010        ['global_average_pooling1d_8[0][0\n","                                                                 ]']                              \n","                                                                                                  \n"," dense_29 (Dense)               (None, 10)           1010        ['global_average_pooling1d_9[0][0\n","                                                                 ]']                              \n","                                                                                                  \n"," dense_32 (Dense)               (None, 10)           1010        ['global_average_pooling1d_10[0][\n","                                                                 0]']                             \n","                                                                                                  \n"," dense_35 (Dense)               (None, 10)           1010        ['global_average_pooling1d_11[0][\n","                                                                 0]']                             \n","                                                                                                  \n"," dense_38 (Dense)               (None, 10)           1010        ['global_average_pooling1d_12[0][\n","                                                                 0]']                             \n","                                                                                                  \n"," dense_41 (Dense)               (None, 10)           1010        ['global_average_pooling1d_13[0][\n","                                                                 0]']                             \n","                                                                                                  \n"," dense_44 (Dense)               (None, 10)           1010        ['global_average_pooling1d_14[0][\n","                                                                 0]']                             \n","                                                                                                  \n"," dense_47 (Dense)               (None, 10)           1010        ['global_average_pooling1d_15[0][\n","                                                                 0]']                             \n","                                                                                                  \n"," dense_50 (Dense)               (None, 10)           1010        ['global_average_pooling1d_16[0][\n","                                                                 0]']                             \n","                                                                                                  \n"," dense_53 (Dense)               (None, 10)           1010        ['global_average_pooling1d_17[0][\n","                                                                 0]']                             \n","                                                                                                  \n"," dense_2 (Dense)                (None, 10)           1010        ['global_average_pooling1d[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n"," tf.math.add (TFOpLambda)       (None, 10)           0           ['dense_5[0][0]']                \n","                                                                                                  \n"," tf.math.add_1 (TFOpLambda)     (None, 10)           0           ['dense_8[0][0]']                \n","                                                                                                  \n"," tf.math.add_2 (TFOpLambda)     (None, 10)           0           ['dense_11[0][0]']               \n","                                                                                                  \n"," tf.math.add_3 (TFOpLambda)     (None, 10)           0           ['dense_14[0][0]']               \n","                                                                                                  \n"," tf.math.add_4 (TFOpLambda)     (None, 10)           0           ['dense_17[0][0]']               \n","                                                                                                  \n"," tf.math.add_5 (TFOpLambda)     (None, 10)           0           ['dense_20[0][0]']               \n","                                                                                                  \n"," tf.math.add_6 (TFOpLambda)     (None, 10)           0           ['dense_23[0][0]']               \n","                                                                                                  \n"," tf.math.add_7 (TFOpLambda)     (None, 10)           0           ['dense_26[0][0]']               \n","                                                                                                  \n"," tf.math.add_8 (TFOpLambda)     (None, 10)           0           ['dense_29[0][0]']               \n","                                                                                                  \n"," tf.math.add_9 (TFOpLambda)     (None, 10)           0           ['dense_32[0][0]']               \n","                                                                                                  \n"," tf.math.add_10 (TFOpLambda)    (None, 10)           0           ['dense_35[0][0]']               \n","                                                                                                  \n"," tf.math.add_11 (TFOpLambda)    (None, 10)           0           ['dense_38[0][0]']               \n","                                                                                                  \n"," tf.math.add_12 (TFOpLambda)    (None, 10)           0           ['dense_41[0][0]']               \n","                                                                                                  \n"," tf.math.add_13 (TFOpLambda)    (None, 10)           0           ['dense_44[0][0]']               \n","                                                                                                  \n"," tf.math.add_14 (TFOpLambda)    (None, 10)           0           ['dense_47[0][0]']               \n","                                                                                                  \n"," tf.math.add_15 (TFOpLambda)    (None, 10)           0           ['dense_50[0][0]']               \n","                                                                                                  \n"," tf.math.add_16 (TFOpLambda)    (None, 10)           0           ['dense_53[0][0]']               \n","                                                                                                  \n"," concatenate (Concatenate)      (None, 180)          0           ['dense_2[0][0]',                \n","                                                                  'tf.math.add[0][0]',            \n","                                                                  'tf.math.add_1[0][0]',          \n","                                                                  'tf.math.add_2[0][0]',          \n","                                                                  'tf.math.add_3[0][0]',          \n","                                                                  'tf.math.add_4[0][0]',          \n","                                                                  'tf.math.add_5[0][0]',          \n","                                                                  'tf.math.add_6[0][0]',          \n","                                                                  'tf.math.add_7[0][0]',          \n","                                                                  'tf.math.add_8[0][0]',          \n","                                                                  'tf.math.add_9[0][0]',          \n","                                                                  'tf.math.add_10[0][0]',         \n","                                                                  'tf.math.add_11[0][0]',         \n","                                                                  'tf.math.add_12[0][0]',         \n","                                                                  'tf.math.add_13[0][0]',         \n","                                                                  'tf.math.add_14[0][0]',         \n","                                                                  'tf.math.add_15[0][0]',         \n","                                                                  'tf.math.add_16[0][0]']         \n","                                                                                                  \n"," tf.expand_dims (TFOpLambda)    (None, 180, 1)       0           ['concatenate[0][0]']            \n","                                                                                                  \n"," layer_normalization_72 (LayerN  (None, 180, 1)      2           ['tf.expand_dims[0][0]']         \n"," ormalization)                                                                                    \n","                                                                                                  \n"," multi_head_attention_36 (Multi  (None, 180, 1)      2521        ['layer_normalization_72[0][0]', \n"," HeadAttention)                                                   'layer_normalization_72[0][0]'] \n","                                                                                                  \n"," dropout_36 (Dropout)           (None, 180, 1)       0           ['multi_head_attention_36[0][0]']\n","                                                                                                  \n"," tf.__operators__.add_72 (TFOpL  (None, 180, 1)      0           ['dropout_36[0][0]',             \n"," ambda)                                                           'tf.expand_dims[0][0]']         \n","                                                                                                  \n"," layer_normalization_73 (LayerN  (None, 180, 1)      2           ['tf.__operators__.add_72[0][0]']\n"," ormalization)                                                                                    \n","                                                                                                  \n"," dense_54 (Dense)               (None, 180, 180)     360         ['layer_normalization_73[0][0]'] \n","                                                                                                  \n"," tf.__operators__.add_73 (TFOpL  (None, 180, 180)    0           ['dense_54[0][0]',               \n"," ambda)                                                           'tf.__operators__.add_72[0][0]']\n","                                                                                                  \n"," layer_normalization_74 (LayerN  (None, 180, 180)    360         ['tf.__operators__.add_73[0][0]']\n"," ormalization)                                                                                    \n","                                                                                                  \n"," multi_head_attention_37 (Multi  (None, 180, 180)    260460      ['layer_normalization_74[0][0]', \n"," HeadAttention)                                                   'layer_normalization_74[0][0]'] \n","                                                                                                  \n"," dropout_37 (Dropout)           (None, 180, 180)     0           ['multi_head_attention_37[0][0]']\n","                                                                                                  \n"," tf.__operators__.add_74 (TFOpL  (None, 180, 180)    0           ['dropout_37[0][0]',             \n"," ambda)                                                           'tf.__operators__.add_73[0][0]']\n","                                                                                                  \n"," layer_normalization_75 (LayerN  (None, 180, 180)    360         ['tf.__operators__.add_74[0][0]']\n"," ormalization)                                                                                    \n","                                                                                                  \n"," dense_55 (Dense)               (None, 180, 180)     32580       ['layer_normalization_75[0][0]'] \n","                                                                                                  \n"," tf.__operators__.add_75 (TFOpL  (None, 180, 180)    0           ['dense_55[0][0]',               \n"," ambda)                                                           'tf.__operators__.add_74[0][0]']\n","                                                                                                  \n"," global_average_pooling1d_18 (G  (None, 180)         0           ['tf.__operators__.add_75[0][0]']\n"," lobalAveragePooling1D)                                                                           \n","                                                                                                  \n"," dropout_38 (Dropout)           (None, 180)          0           ['global_average_pooling1d_18[0][\n","                                                                 0]']                             \n","                                                                                                  \n"," dense_56 (Dense)               (None, 100)          18100       ['dropout_38[0][0]']             \n","                                                                                                  \n"," dropout_39 (Dropout)           (None, 100)          0           ['dense_56[0][0]']               \n","                                                                                                  \n"," dense_57 (Dense)               (None, 20)           2020        ['dropout_39[0][0]']             \n","                                                                                                  \n"," dropout_40 (Dropout)           (None, 20)           0           ['dense_57[0][0]']               \n","                                                                                                  \n"," dense_58 (Dense)               (None, 5)            105         ['dropout_40[0][0]']             \n","                                                                                                  \n","==================================================================================================\n","Total params: 2,005,540\n","Trainable params: 2,005,540\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","None\n","fold 9\n","Y_train\n","58732\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/structured_function.py:265: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n","  \"Even though the `tf.config.experimental_run_functions_eagerly` \"\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","534/534 [==============================] - ETA: 0s - loss: 0.4333 - accuracy: 0.4429\n","Epoch 1: val_accuracy improved from -inf to 0.65647, saving model to output/train_severity_02_22/13_36/weights_9.hdf5\n","534/534 [==============================] - 926s 2s/step - loss: 0.4333 - accuracy: 0.4429 - val_loss: 0.3234 - val_accuracy: 0.6565\n","Epoch 2/100\n","534/534 [==============================] - ETA: 0s - loss: 0.3461 - accuracy: 0.5932\n","Epoch 2: val_accuracy did not improve from 0.65647\n","534/534 [==============================] - 917s 2s/step - loss: 0.3461 - accuracy: 0.5932 - val_loss: 0.2906 - val_accuracy: 0.6351\n","Epoch 3/100\n","534/534 [==============================] - ETA: 0s - loss: 0.2908 - accuracy: 0.6824\n","Epoch 3: val_accuracy improved from 0.65647 to 0.77018, saving model to output/train_severity_02_22/13_36/weights_9.hdf5\n","534/534 [==============================] - 917s 2s/step - loss: 0.2908 - accuracy: 0.6824 - val_loss: 0.2229 - val_accuracy: 0.7702\n","Epoch 4/100\n","534/534 [==============================] - ETA: 0s - loss: 0.2460 - accuracy: 0.7442\n","Epoch 4: val_accuracy improved from 0.77018 to 0.79555, saving model to output/train_severity_02_22/13_36/weights_9.hdf5\n","534/534 [==============================] - 912s 2s/step - loss: 0.2460 - accuracy: 0.7442 - val_loss: 0.2046 - val_accuracy: 0.7956\n","Epoch 5/100\n","534/534 [==============================] - ETA: 0s - loss: 0.2137 - accuracy: 0.7844\n","Epoch 5: val_accuracy improved from 0.79555 to 0.83167, saving model to output/train_severity_02_22/13_36/weights_9.hdf5\n","534/534 [==============================] - 918s 2s/step - loss: 0.2137 - accuracy: 0.7844 - val_loss: 0.1696 - val_accuracy: 0.8317\n","Epoch 6/100\n","534/534 [==============================] - ETA: 0s - loss: 0.1907 - accuracy: 0.8126\n","Epoch 6: val_accuracy did not improve from 0.83167\n","534/534 [==============================] - 926s 2s/step - loss: 0.1907 - accuracy: 0.8126 - val_loss: 0.1916 - val_accuracy: 0.8061\n","Epoch 7/100\n","534/534 [==============================] - ETA: 0s - loss: 0.1716 - accuracy: 0.8348\n","Epoch 7: val_accuracy improved from 0.83167 to 0.83495, saving model to output/train_severity_02_22/13_36/weights_9.hdf5\n","534/534 [==============================] - 923s 2s/step - loss: 0.1716 - accuracy: 0.8348 - val_loss: 0.1634 - val_accuracy: 0.8350\n","Epoch 8/100\n","534/534 [==============================] - ETA: 0s - loss: 0.1579 - accuracy: 0.8500\n","Epoch 8: val_accuracy did not improve from 0.83495\n","534/534 [==============================] - 924s 2s/step - loss: 0.1579 - accuracy: 0.8500 - val_loss: 0.1618 - val_accuracy: 0.8294\n","Epoch 9/100\n","534/534 [==============================] - ETA: 0s - loss: 0.1462 - accuracy: 0.8622\n","Epoch 9: val_accuracy did not improve from 0.83495\n","534/534 [==============================] - 921s 2s/step - loss: 0.1462 - accuracy: 0.8622 - val_loss: 0.1742 - val_accuracy: 0.8170\n","Epoch 10/100\n","534/534 [==============================] - ETA: 0s - loss: 0.1373 - accuracy: 0.8716\n","Epoch 10: val_accuracy did not improve from 0.83495\n","534/534 [==============================] - 918s 2s/step - loss: 0.1373 - accuracy: 0.8716 - val_loss: 0.1609 - val_accuracy: 0.8312\n","Epoch 11/100\n","534/534 [==============================] - ETA: 0s - loss: 0.1280 - accuracy: 0.8829\n","Epoch 11: val_accuracy improved from 0.83495 to 0.86151, saving model to output/train_severity_02_22/13_36/weights_9.hdf5\n","534/534 [==============================] - 907s 2s/step - loss: 0.1280 - accuracy: 0.8829 - val_loss: 0.1420 - val_accuracy: 0.8615\n","Epoch 12/100\n","534/534 [==============================] - ETA: 0s - loss: 0.1233 - accuracy: 0.8866\n","Epoch 12: val_accuracy did not improve from 0.86151\n","534/534 [==============================] - 917s 2s/step - loss: 0.1233 - accuracy: 0.8866 - val_loss: 0.1438 - val_accuracy: 0.8455\n","Epoch 13/100\n","534/534 [==============================] - ETA: 0s - loss: 0.1163 - accuracy: 0.8928\n","Epoch 13: val_accuracy did not improve from 0.86151\n","534/534 [==============================] - 932s 2s/step - loss: 0.1163 - accuracy: 0.8928 - val_loss: 0.1462 - val_accuracy: 0.8575\n","Epoch 14/100\n","534/534 [==============================] - ETA: 0s - loss: 0.1118 - accuracy: 0.8965\n","Epoch 14: val_accuracy did not improve from 0.86151\n","534/534 [==============================] - 913s 2s/step - loss: 0.1118 - accuracy: 0.8965 - val_loss: 0.1985 - val_accuracy: 0.8138\n","Epoch 15/100\n","534/534 [==============================] - ETA: 0s - loss: 0.1091 - accuracy: 0.9000\n","Epoch 15: val_accuracy did not improve from 0.86151\n","534/534 [==============================] - 900s 2s/step - loss: 0.1091 - accuracy: 0.9000 - val_loss: 0.1604 - val_accuracy: 0.8333\n","Epoch 16/100\n","534/534 [==============================] - ETA: 0s - loss: 0.1033 - accuracy: 0.9070\n","Epoch 16: val_accuracy did not improve from 0.86151\n","534/534 [==============================] - 917s 2s/step - loss: 0.1033 - accuracy: 0.9070 - val_loss: 0.1552 - val_accuracy: 0.8496\n","Epoch 17/100\n","534/534 [==============================] - ETA: 0s - loss: 0.1022 - accuracy: 0.9074\n","Epoch 17: val_accuracy did not improve from 0.86151\n","534/534 [==============================] - 917s 2s/step - loss: 0.1022 - accuracy: 0.9074 - val_loss: 0.1761 - val_accuracy: 0.8205\n","Epoch 18/100\n","534/534 [==============================] - ETA: 0s - loss: 0.0971 - accuracy: 0.9120\n","Epoch 18: val_accuracy did not improve from 0.86151\n","534/534 [==============================] - 908s 2s/step - loss: 0.0971 - accuracy: 0.9120 - val_loss: 0.1481 - val_accuracy: 0.8584\n","Epoch 19/100\n","534/534 [==============================] - ETA: 0s - loss: 0.0944 - accuracy: 0.9140\n","Epoch 19: val_accuracy did not improve from 0.86151\n","534/534 [==============================] - 906s 2s/step - loss: 0.0944 - accuracy: 0.9140 - val_loss: 0.1453 - val_accuracy: 0.8615\n","Epoch 20/100\n","534/534 [==============================] - ETA: 0s - loss: 0.0927 - accuracy: 0.9173\n","Epoch 20: val_accuracy improved from 0.86151 to 0.87987, saving model to output/train_severity_02_22/13_36/weights_9.hdf5\n","534/534 [==============================] - 917s 2s/step - loss: 0.0927 - accuracy: 0.9173 - val_loss: 0.1314 - val_accuracy: 0.8799\n","Epoch 21/100\n","534/534 [==============================] - ETA: 0s - loss: 0.0900 - accuracy: 0.9178\n","Epoch 21: val_accuracy did not improve from 0.87987\n","534/534 [==============================] - 922s 2s/step - loss: 0.0900 - accuracy: 0.9178 - val_loss: 0.1668 - val_accuracy: 0.8466\n","Epoch 22/100\n","534/534 [==============================] - ETA: 0s - loss: 0.0879 - accuracy: 0.9213\n","Epoch 22: val_accuracy did not improve from 0.87987\n","534/534 [==============================] - 915s 2s/step - loss: 0.0879 - accuracy: 0.9213 - val_loss: 0.1630 - val_accuracy: 0.8381\n","Epoch 23/100\n","534/534 [==============================] - ETA: 0s - loss: 0.0853 - accuracy: 0.9213\n","Epoch 23: val_accuracy did not improve from 0.87987\n","534/534 [==============================] - 906s 2s/step - loss: 0.0853 - accuracy: 0.9213 - val_loss: 0.1682 - val_accuracy: 0.8478\n","Epoch 24/100\n","534/534 [==============================] - ETA: 0s - loss: 0.0844 - accuracy: 0.9236\n","Epoch 24: val_accuracy did not improve from 0.87987\n","534/534 [==============================] - 906s 2s/step - loss: 0.0844 - accuracy: 0.9236 - val_loss: 0.1455 - val_accuracy: 0.8658\n","Epoch 25/100\n","534/534 [==============================] - ETA: 0s - loss: 0.0813 - accuracy: 0.9254\n","Epoch 25: val_accuracy did not improve from 0.87987\n","534/534 [==============================] - 907s 2s/step - loss: 0.0813 - accuracy: 0.9254 - val_loss: 0.1606 - val_accuracy: 0.8596\n","Epoch 26/100\n","534/534 [==============================] - ETA: 0s - loss: 0.0812 - accuracy: 0.9253\n","Epoch 26: val_accuracy did not improve from 0.87987\n","534/534 [==============================] - 914s 2s/step - loss: 0.0812 - accuracy: 0.9253 - val_loss: 0.1545 - val_accuracy: 0.8532\n","Epoch 27/100\n","534/534 [==============================] - ETA: 0s - loss: 0.0795 - accuracy: 0.9269\n","Epoch 27: val_accuracy did not improve from 0.87987\n","534/534 [==============================] - 911s 2s/step - loss: 0.0795 - accuracy: 0.9269 - val_loss: 0.1462 - val_accuracy: 0.8736\n","Epoch 28/100\n","534/534 [==============================] - ETA: 0s - loss: 0.0776 - accuracy: 0.9300\n","Epoch 28: val_accuracy did not improve from 0.87987\n","534/534 [==============================] - 912s 2s/step - loss: 0.0776 - accuracy: 0.9300 - val_loss: 0.1663 - val_accuracy: 0.8518\n","Epoch 29/100\n","534/534 [==============================] - ETA: 0s - loss: 0.0778 - accuracy: 0.9298\n","Epoch 29: val_accuracy did not improve from 0.87987\n","534/534 [==============================] - 912s 2s/step - loss: 0.0778 - accuracy: 0.9298 - val_loss: 0.1401 - val_accuracy: 0.8727\n","Epoch 30/100\n","534/534 [==============================] - ETA: 0s - loss: 0.0755 - accuracy: 0.9325\n","Epoch 30: val_accuracy did not improve from 0.87987\n","534/534 [==============================] - 900s 2s/step - loss: 0.0755 - accuracy: 0.9325 - val_loss: 0.1628 - val_accuracy: 0.8502\n","Epoch 31/100\n","534/534 [==============================] - ETA: 0s - loss: 0.0752 - accuracy: 0.9311\n","Epoch 31: val_accuracy did not improve from 0.87987\n","534/534 [==============================] - 907s 2s/step - loss: 0.0752 - accuracy: 0.9311 - val_loss: 0.1448 - val_accuracy: 0.8746\n","Epoch 32/100\n","534/534 [==============================] - ETA: 0s - loss: 0.0737 - accuracy: 0.9333\n","Epoch 32: val_accuracy did not improve from 0.87987\n","534/534 [==============================] - 914s 2s/step - loss: 0.0737 - accuracy: 0.9333 - val_loss: 0.1620 - val_accuracy: 0.8603\n","Epoch 33/100\n","534/534 [==============================] - ETA: 0s - loss: 0.0738 - accuracy: 0.9321\n","Epoch 33: val_accuracy did not improve from 0.87987\n","534/534 [==============================] - 901s 2s/step - loss: 0.0738 - accuracy: 0.9321 - val_loss: 0.1708 - val_accuracy: 0.8494\n","Epoch 34/100\n","534/534 [==============================] - ETA: 0s - loss: 0.0729 - accuracy: 0.9348\n","Epoch 34: val_accuracy did not improve from 0.87987\n","534/534 [==============================] - 899s 2s/step - loss: 0.0729 - accuracy: 0.9348 - val_loss: 0.1582 - val_accuracy: 0.8572\n","Epoch 35/100\n","534/534 [==============================] - ETA: 0s - loss: 0.0719 - accuracy: 0.9339\n","Epoch 35: val_accuracy did not improve from 0.87987\n","534/534 [==============================] - 896s 2s/step - loss: 0.0719 - accuracy: 0.9339 - val_loss: 0.1447 - val_accuracy: 0.8709\n","Epoch 36/100\n","534/534 [==============================] - ETA: 0s - loss: 0.0713 - accuracy: 0.9355\n","Epoch 36: val_accuracy did not improve from 0.87987\n","534/534 [==============================] - 893s 2s/step - loss: 0.0713 - accuracy: 0.9355 - val_loss: 0.1413 - val_accuracy: 0.8658\n","Epoch 37/100\n","534/534 [==============================] - ETA: 0s - loss: 0.0704 - accuracy: 0.9359\n","Epoch 37: val_accuracy did not improve from 0.87987\n","534/534 [==============================] - 893s 2s/step - loss: 0.0704 - accuracy: 0.9359 - val_loss: 0.1756 - val_accuracy: 0.8417\n","Epoch 38/100\n","534/534 [==============================] - ETA: 0s - loss: 0.0694 - accuracy: 0.9361\n","Epoch 38: val_accuracy did not improve from 0.87987\n","534/534 [==============================] - 903s 2s/step - loss: 0.0694 - accuracy: 0.9361 - val_loss: 0.1567 - val_accuracy: 0.8623\n","Epoch 39/100\n","534/534 [==============================] - ETA: 0s - loss: 0.0677 - accuracy: 0.9379\n","Epoch 39: val_accuracy did not improve from 0.87987\n","534/534 [==============================] - 912s 2s/step - loss: 0.0677 - accuracy: 0.9379 - val_loss: 0.1601 - val_accuracy: 0.8658\n","Epoch 40/100\n","534/534 [==============================] - ETA: 0s - loss: 0.0673 - accuracy: 0.9388\n","Epoch 40: val_accuracy did not improve from 0.87987\n","534/534 [==============================] - 903s 2s/step - loss: 0.0673 - accuracy: 0.9388 - val_loss: 0.1891 - val_accuracy: 0.8357\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/nadam.py:73: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(Nadam, self).__init__(name, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Validation !!\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/structured_function.py:265: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n","  \"Even though the `tf.config.experimental_run_functions_eagerly` \"\n"]},{"output_type":"stream","name":"stdout","text":["5/5 [==============================] - 2s 346ms/step - loss: 0.5879 - accuracy: 0.5260\n","8/8 [==============================] - 3s 351ms/step - loss: 0.0505 - accuracy: 0.9419\n","8/8 [==============================] - 3s 349ms/step - loss: 0.1099 - accuracy: 0.9295\n","6/6 [==============================] - 2s 356ms/step - loss: 0.0094 - accuracy: 0.9941\n","8/8 [==============================] - 3s 345ms/step - loss: 0.0150 - accuracy: 0.9959\n","8/8 [==============================] - 3s 346ms/step - loss: 0.0337 - accuracy: 0.9627\n","8/8 [==============================] - 3s 347ms/step - loss: 0.3050 - accuracy: 0.6432\n","8/8 [==============================] - 3s 347ms/step - loss: 0.0562 - accuracy: 0.9544\n","8/8 [==============================] - 3s 349ms/step - loss: 0.0998 - accuracy: 0.9129\n","8/8 [==============================] - 3s 347ms/step - loss: 0.4438 - accuracy: 0.6183\n","9/9 [==============================] - 3s 348ms/step - loss: 0.0406 - accuracy: 0.9636\n","8/8 [==============================] - 3s 353ms/step - loss: 0.0150 - accuracy: 0.9834\n","11/11 [==============================] - 4s 348ms/step - loss: 0.0100 - accuracy: 0.9969\n","8/8 [==============================] - 3s 349ms/step - loss: 0.1212 - accuracy: 0.8465\n","6/6 [==============================] - 2s 349ms/step - loss: 0.5173 - accuracy: 0.3200\n","8/8 [==============================] - 3s 349ms/step - loss: 0.0504 - accuracy: 0.9751\n","8/8 [==============================] - 3s 346ms/step - loss: 0.1582 - accuracy: 0.8465\n","8/8 [==============================] - 3s 346ms/step - loss: 0.1194 - accuracy: 0.9022\n","10/10 [==============================] - 4s 355ms/step - loss: 0.0033 - accuracy: 0.9968\n","6/6 [==============================] - 2s 354ms/step - loss: 0.1083 - accuracy: 0.9409\n","3/3 [==============================] - 1s 363ms/step - loss: 1.2880 - accuracy: 0.0526\n","8/8 [==============================] - 3s 350ms/step - loss: 0.3023 - accuracy: 0.7012\n","8/8 [==============================] - 3s 348ms/step - loss: 0.0550 - accuracy: 0.9585\n","8/8 [==============================] - 3s 354ms/step - loss: 0.0165 - accuracy: 0.9917\n","4/4 [==============================] - 1s 349ms/step - loss: 0.0502 - accuracy: 0.9741\n","6/6 [==============================] - 2s 354ms/step - loss: 0.0253 - accuracy: 0.9832\n","5/5 [==============================] - 2s 353ms/step - loss: 0.0220 - accuracy: 0.9808\n","8/8 [==============================] - 3s 354ms/step - loss: 0.0637 - accuracy: 0.9544\n","8/8 [==============================] - 3s 355ms/step - loss: 0.1219 - accuracy: 0.8963\n","8/8 [==============================] - 3s 354ms/step - loss: 0.0526 - accuracy: 0.9461\n","              precision    recall  f1-score   support\n","\n","           0       0.75      1.00      0.86         9\n","           1       1.00      0.50      0.67         2\n","           2       1.00      1.00      1.00         7\n","           3       1.00      0.60      0.75         5\n","           4       1.00      1.00      1.00         7\n","\n","    accuracy                           0.90        30\n","   macro avg       0.95      0.82      0.85        30\n","weighted avg       0.93      0.90      0.89        30\n","\n","{'0': {'precision': 0.75, 'recall': 1.0, 'f1-score': 0.8571428571428571, 'support': 9}, '1': {'precision': 1.0, 'recall': 0.5, 'f1-score': 0.6666666666666666, 'support': 2}, '2': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 7}, '3': {'precision': 1.0, 'recall': 0.6, 'f1-score': 0.7499999999999999, 'support': 5}, '4': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 7}, 'accuracy': 0.9, 'macro avg': {'precision': 0.95, 'recall': 0.82, 'f1-score': 0.8547619047619047, 'support': 30}, 'weighted avg': {'precision': 0.925, 'recall': 0.9, 'f1-score': 0.8932539682539683, 'support': 30}}\n"]}],"source":["import numpy as np\n","import argparse\n","# fix random seed for reproducibility\n","np.random.seed(2) #2\n","from tensorflow.keras import optimizers\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger\n","import datetime\n","import os\n","\n","#from src.data_utils2 import Datas\n","#from src.results import Results,Results_level\n","\n","#from src.algo import multiple_cnn1D, multiple_cnn1D5_level\n","#from src.data_utils import Data\n","\n","def train( model, datas, lr, log_filename, filename):\n","    \"\"\"\n","\n","    :param model: Initial untrained model\n","    :param datas:  data object\n","    :param lr: learning rate\n","    :param log_filename: filename where the training results will be saved ( for each epoch)\n","    :param filename: file where the weights will be saved\n","    :return:  trained model\n","    \"\"\"\n","    X_train = datas.X_train\n","    y_train = datas.y_train\n","    X_val = datas.X_val\n","    y_val = datas.y_val\n","    \n","    \n","    logger = CSVLogger(log_filename, separator=',', append=True)\n","    for i in (np.arange(1,4)*5):  # 10-20    1-10\n","\n","        checkpointer = ModelCheckpoint(filepath=filename , monitor='val_accuracy', verbose=1, save_best_only=True,save_freq='epoch')\n","        early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=20, verbose=0, mode='auto')\n","\n","        callbacks_list = [checkpointer, early_stopping, logger]\n","        print(\"Y_train\")\n","        print(len(y_train))\n","        history = model.fit(np.split(X_train,X_train.shape[2], axis=2), \\\n","                            # history  = model.fit(X_data,\\\n","                            y_train, \\\n","                            verbose=1, \\\n","                            shuffle=True, \\\n","                            epochs= 100,\\\n","                            batch_size=110, \\\n","                            # validation_data=(X_val, y_val),\\\n","                            validation_data=(np.split(X_val, X_val.shape[2], axis=2), y_val), \\\n","                            callbacks=callbacks_list)\n","\n","        model.load_weights(filename)\n","        lr =  lr / 2\n","        rms = optimizers.Nadam(lr=lr)\n","        model.compile(loss='binary_crossentropy', optimizer=rms, metrics=['accuracy'])\n","        return model\n","\n","\n","def ablation_study(args):\n","    '''\n","    Function that performs the ablation study\n","    :param args:  Input arguments\n","    :return:pos\n","    '''\n","    features = np.arange(1, 19)\n","    folder = os.path.join(args.output, args.exp_name  + '_' + datetime.datetime.now().strftime(\"%m_%d\"),\n","                             datetime.datetime.now().strftime(\n","                                 \"%H_%M\"))\n","    if not os.path.exists(folder):\n","        os.makedirs(folder)\n","    for j in range(4, 9):\n","        exp_name = args.exp_name + str(j)\n","        subfolder = os.path.join(folder, 'feature_' + str(j) )\n","        file_result_patients = os.path.join(subfolder,'res_pat.csv')\n","        file_result_segments = os.path.join(subfolder,'res_seg.csv')\n","        filename = subfolder + \"weights.hdf5\"\n","        model_file = os.path.join(subfolder, \"model.json\")\n","        if not os.path.exists(subfolder):\n","            os.makedirs(subfolder)\n","\n","        feature_delete = j\n","        feature_delete_r = j + 9\n","        features_i = np.delete(features, [feature_delete, feature_delete_r])\n","        val_results = Results(file_result_segments, file_result_patients)\n","        #datas = Datas(args.input_data, 1,  100, features=features_i)\n","        #datas.load(norm=None)\n","        datas = Data(args.input_data, 1, 100, pk_level=False)\n","        for i in range(0, 10):\n","            lr = 0.001\n","            print('fold', str(i))\n","            log_filename = os.path.join(subfolder, \"training_\" + str(i) + \".csv\")\n","            w_filename = os.path.join(subfolder, \"weights_\" + str(i) + \".hdf5\")\n","            datas.separate_fold(i)\n","            model = multiple_transformer(datas.X_data.shape[2])\n","            model_json = model.to_json()\n","            with open(model_file, \"w\") as json_file:\n","                json_file.write(model_json)\n","\n","            model = train(model, datas, lr, log_filename, w_filename)\n","\n","            print('Validation !!!!!!!')\n","            val_results.validate_patient(model, datas.X_val, datas.y_val, datas.count_val)\n","\n","\n","def train_classifier(args):\n","    '''\n","    Function that performs the detection of Parkinson\n","    :param args: Input arguments\n","    :return:\n","    '''\n","    exp_name = args.exp_name\n","    subfolder = os.path.join(args.output, exp_name +'_' + datetime.datetime.now().strftime(\"%m_%d\"), datetime.datetime.now().strftime(\n","        \"%H_%M\"))\n","    file_result_patients = os.path.join(subfolder,'res_pat.csv')\n","    file_result_segments = os.path.join(subfolder,'res_seg.csv')\n","    model_file = os.path.join(subfolder, \"model.json\")\n","    if not os.path.exists(subfolder):\n","        os.makedirs(subfolder)\n","\n","    val_results = Results(file_result_segments, file_result_patients)\n","    datas = Data(args.input_data, 1, 100, pk_level= False )\n","\n","    for i in range(0, 10):\n","        lr = 0.001\n","        model = multiple_transformer(datas.X_data.shape[2])\n","        model_json = model.to_json()\n","        with open(model_file, \"w\") as json_file:\n","            json_file.write(model_json)\n","\n","        print('fold', str(i))\n","        datas.separate_fold(i)\n","        log_filename = os.path.join( subfolder ,\"training_\" + str(i) + \".csv\")\n","        w_filename = os.path.join(subfolder ,\"weights_\" + str(i) + \".hdf5\")\n","        model = train(model, datas, lr, log_filename, w_filename)\n","        print('Validation !!')\n","        val_results.validate_patient(model, datas.X_val, datas.y_val, datas.count_val)\n","\n","def train_severity(args):\n","    '''\n","\n","    :param args: Input arguments\n","    :return:\n","    '''\n","    features = np.arange(1, 19)\n","\n","\n","    exp_name = args.exp_name\n","\n","    subfolder = os.path.join(args.output, exp_name +'_' + datetime.datetime.now().strftime(\"%m_%d\"), datetime.datetime.now().strftime(\n","        \"%H_%M\"))\n","    if not os.path.exists(subfolder):\n","        os.makedirs(subfolder)\n","    file_result_patients = os.path.join(subfolder ,'res_pat.csv')\n","    file_result_segments = os.path.join(subfolder ,'res_seg.csv')\n","\n","    model_file = os.path.join(subfolder, \"model.json\")\n","\n","    val_results = Results_level(file_result_segments, file_result_patients, subfolder )\n","    datas = Data(args.input_data, 1, 100)  # modif\n","    lr = 0.001\n","    for i in range(9,10):\n","\n","        model = multiple_transformer_5_level(datas.X_data.shape[2])\n","        model_json = model.to_json()\n","        with open(model_file, \"w\") as json_file:\n","            json_file.write(model_json)\n","        print('fold', str(i))\n","        datas.separate_fold(i)\n","        log_filename = os.path.join(subfolder, \"trainig\" + str(i) + \".csv\")\n","        w_filename = os.path.join(subfolder ,\"weights_\" + str(i) + \".hdf5\")\n","        model = train(model, datas, lr, log_filename,  w_filename )\n","        print('Validation !!')\n","        val_results.validate_patient(model, datas.X_val, datas.y_val, datas.count_val)\n","\n","\n","if __name__ == '__main__':\n","    \n","    parser = argparse.ArgumentParser()\n","    parser.add_argument(\"-input_data\", default='../data', type=str)\n","    #' \n","    parser.add_argument(\"-exp_name\", default='train_severity', type=str, help = 'ablation ;train_classifier ; train_severity')\n","    parser.add_argument(\"-output\", default='output', type=str)\n","    args = parser.parse_args(args=[])\n","    if not os.path.exists(args.output):\n","        os.makedirs(args.output)\n","    if args.exp_name == 'ablation' :\n","        ablation_study(args)\n","    if args.exp_name == 'train_classifier' :\n","        train_classifier(args)\n","    if args.exp_name == 'train_severity':\n","        train_severity(args)\n"],"id":"31745805"}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"Copie de TransformatorParkinson V4.ipynb","provenance":[{"file_id":"10em1Cu4WsSJmZWTUOe_fJrdWAEhku5WI","timestamp":1636780860062},{"file_id":"1qxkcq304vVzhx97N4TqQA9NOJG7Bb_ft","timestamp":1635861057795},{"file_id":"1Ou3rbOWkof17i1_HqFAys9EjwJfMAwGw","timestamp":1631911337205},{"file_id":"https://github.com/minh28/Parkinson/blob/master/src/Parkinson.ipynb","timestamp":1631224609589}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":5}